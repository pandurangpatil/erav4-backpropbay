{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CIFAR-100 Model (Local Mac)\n",
    "This notebook trains a model on CIFAR-100 locally on Mac with the specified configuration.\n",
    "\n",
    "**Training Command:**\n",
    "```bash\n",
    "python train.py --epochs 50 --batch-size 256 --model resnet50 --scheduler onecycle --lr-finder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENVIRONMENT INFORMATION\n",
      "======================================================================\n",
      "Python Version: 3.12.3 (main, Oct  7 2025, 19:27:29) [Clang 17.0.0 (clang-1700.0.13.5)]\n",
      "Platform: macOS-15.5-arm64-arm-64bit\n",
      "Processor: arm\n",
      "Working Directory: /Users/pandurang/projects/pandurang/erav4-backpropbay/session8-more-trials\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENVIRONMENT INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Working Directory: {os.getcwd()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU/MPS Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PYTORCH & GPU DETECTION\n",
      "======================================================================\n",
      "PyTorch Version: 2.9.0\n",
      "✓ Apple MPS (Metal Performance Shaders) is available\n",
      "  This Mac has Apple Silicon GPU acceleration\n",
      "✓ Using device: mps\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PYTORCH & GPU DETECTION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    \n",
    "    # Check for CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✓ CUDA is available\")\n",
    "        print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "        device = torch.device('cuda')\n",
    "    # Check for MPS (Apple Silicon)\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        print(f\"✓ Apple MPS (Metal Performance Shaders) is available\")\n",
    "        print(f\"  This Mac has Apple Silicon GPU acceleration\")\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        print(f\"⚠ No GPU detected. Training will use CPU\")\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    print(f\"✓ Using device: {device}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠ PyTorch not installed. Will install dependencies in next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.9.0)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: torchsummary>=0.1.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: torchinfo>=1.8.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.10.7)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (2.2.6)\n",
      "Requirement already satisfied: plotille>=5.0.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (5.0.0)\n",
      "Requirement already satisfied: albumentations>=1.3.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (2.0.8)\n",
      "Requirement already satisfied: huggingface_hub>=0.20.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.35.3)\n",
      "Requirement already satisfied: filelock in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from torchvision>=0.15.0->-r requirements.txt (line 2)) (12.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (1.16.2)\n",
      "Requirement already satisfied: PyYAML in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (2.12.3)\n",
      "Requirement already satisfied: albucore==0.0.24 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from albumentations>=1.3.0->-r requirements.txt (line 9)) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 9)) (4.2.1)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 9)) (6.5.3)\n",
      "Requirement already satisfied: requests in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (1.1.10)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 9)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pandurang/.pyenv/versions/3.12.3/envs/session8-more-trials/lib/python3.12/site-packages (from requests->huggingface_hub>=0.20.0->-r requirements.txt (line 10)) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies from requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Verify Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LIBRARY VERSIONS\n",
      "======================================================================\n",
      "PyTorch: 2.9.0\n",
      "TorchVision: 0.24.0\n",
      "NumPy: 2.2.6\n",
      "Matplotlib: 3.10.7\n",
      "Albumentations: 2.0.8\n",
      "TQDM: 4.67.1\n",
      "======================================================================\n",
      "✓ All dependencies successfully imported\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "import torchinfo\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import numpy\n",
    "import plotille\n",
    "import albumentations\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LIBRARY VERSIONS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"TorchVision: {torchvision.__version__}\")\n",
    "print(f\"NumPy: {numpy.__version__}\")\n",
    "print(f\"Matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"Albumentations: {albumentations.__version__}\")\n",
    "print(f\"TQDM: {tqdm.__version__}\")\n",
    "print(\"=\"*70)\n",
    "print(\"✓ All dependencies successfully imported\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFYING TRAINING FILES\n",
      "======================================================================\n",
      "✓ train.py\n",
      "✓ model.py\n",
      "✓ config.json\n",
      "✓ requirements.txt\n",
      "======================================================================\n",
      "✓ All required files found\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFYING TRAINING FILES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "required_files = [\n",
    "    'train.py',\n",
    "    'model.py',\n",
    "    'config.json',\n",
    "    'requirements.txt'\n",
    "]\n",
    "\n",
    "all_exist = True\n",
    "for file in required_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"{status} {file}\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "print(\"=\"*70)\n",
    "if all_exist:\n",
    "    print(\"✓ All required files found\")\n",
    "else:\n",
    "    print(\"⚠ Some files are missing. Please check your directory.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Training Configuration\n",
    "\n",
    "The training will use the following configuration:\n",
    "\n",
    "- **Model**: resnet50\n",
    "- **Epochs**: 50\n",
    "- **Batch Size**: 256\n",
    "- **Scheduler**: OneCycle Learning Rate Policy\n",
    "- **LR Finder**: Enabled (will automatically find optimal learning rate)\n",
    "\n",
    "The LR Finder will:\n",
    "1. Run a learning rate range test before training\n",
    "2. Automatically determine the best `max_lr` and `base_lr` for OneCycle scheduler\n",
    "3. Save the LR finder plot to `checkpoint_N/lr_finder_plot.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "**Note:** This will take a significant amount of time depending on your hardware.\n",
    "\n",
    "Training progress will be displayed below with:\n",
    "- Real-time loss and accuracy metrics\n",
    "- Learning rate schedule visualization\n",
    "- Checkpoint saving at key epochs\n",
    "- Early stopping if no improvement\n",
    "\n",
    "**Expected behavior:**\n",
    "1. LR Finder will run first (3 epochs of range testing)\n",
    "2. LR Finder will suggest optimal learning rates\n",
    "3. Main training will begin with the suggested learning rates\n",
    "4. Model checkpoints will be saved to `checkpoint_N/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded LR Finder config from: ./config.json\n",
      "\n",
      "======================================================================\n",
      "GPU DETECTION AND CONFIGURATION\n",
      "======================================================================\n",
      "✓ Apple MPS (Metal Performance Shaders) is available\n",
      "✓ Using device: mps\n",
      "✓ PyTorch Version: 2.9.0\n",
      "======================================================================\n",
      "\n",
      "✓ Loaded OneCycleLR config from: ./config.json\n",
      "  Parameters: {'max_lr': 0.1, 'pct_start': 0.3, 'anneal_strategy': 'cos', 'div_factor': 25.0, 'final_div_factor': 10000.0, 'three_phase': False}\n",
      "/Users/pandurang/projects/pandurang/erav4-backpropbay/session8-more-trials/train.py:812: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler() if self.use_amp else None\n",
      "/Users/pandurang/.pyenv/versions/session8-more-trials/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:31: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  super().__init__(\n",
      "📁 Creating checkpoint folder: ./checkpoint_10\n",
      "Training resnet50 for 50 epochs\n",
      "======================================================================\n",
      "Configuration:\n",
      "  - Model: WideResNet-28-10 (36.5M parameters)\n",
      "  - Dataset: CIFAR-100\n",
      "  - Batch Size: 256\n",
      "  - Epochs: 50\n",
      "  - Scheduler: ONECYCLE\n",
      "    • OneCycleLR config: defaults\n",
      "  - MixUp: True (alpha=0.2)\n",
      "  - Label Smoothing: 0.1\n",
      "  - Mixed Precision: True\n",
      "  - Gradient Clipping: 1.0\n",
      "  - Checkpoint Epochs: [10, 20, 25, 30, 40, 50, 60, 75, 90]\n",
      "  - HuggingFace Upload: DISABLED (no token or repo provided)\n",
      "  ⚠ Warning: Final model will NOT be uploaded to HuggingFace\n",
      "  ℹ Models will be saved locally to ./checkpoints/\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Model Architecture Summary\n",
      "======================================================================\n",
      "Device: mps\n",
      "Device Type: Apple Metal Performance Shaders (MPS)\n",
      "\n",
      "Model Summary:\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet50                                 [1, 100]                  --\n",
      "├─Conv2d: 1-1                            [1, 64, 32, 32]           1,728\n",
      "├─BatchNorm2d: 1-2                       [1, 64, 32, 32]           128\n",
      "├─ReLU: 1-3                              [1, 64, 32, 32]           --\n",
      "├─Sequential: 1-4                        [1, 256, 32, 32]          --\n",
      "│    └─Bottleneck: 2-1                   [1, 256, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-1                  [1, 64, 32, 32]           4,096\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 64, 32, 32]           128\n",
      "│    │    └─ReLU: 3-3                    [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-4                  [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-5             [1, 64, 32, 32]           128\n",
      "│    │    └─ReLU: 3-6                    [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-7                  [1, 256, 32, 32]          16,384\n",
      "│    │    └─BatchNorm2d: 3-8             [1, 256, 32, 32]          512\n",
      "│    │    └─Sequential: 3-9              [1, 256, 32, 32]          16,896\n",
      "│    │    └─ReLU: 3-10                   [1, 256, 32, 32]          --\n",
      "│    └─Bottleneck: 2-2                   [1, 256, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-11                 [1, 64, 32, 32]           16,384\n",
      "│    │    └─BatchNorm2d: 3-12            [1, 64, 32, 32]           128\n",
      "│    │    └─ReLU: 3-13                   [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-14                 [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-15            [1, 64, 32, 32]           128\n",
      "│    │    └─ReLU: 3-16                   [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-17                 [1, 256, 32, 32]          16,384\n",
      "│    │    └─BatchNorm2d: 3-18            [1, 256, 32, 32]          512\n",
      "│    │    └─ReLU: 3-19                   [1, 256, 32, 32]          --\n",
      "│    └─Bottleneck: 2-3                   [1, 256, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-20                 [1, 64, 32, 32]           16,384\n",
      "│    │    └─BatchNorm2d: 3-21            [1, 64, 32, 32]           128\n",
      "│    │    └─ReLU: 3-22                   [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-23                 [1, 64, 32, 32]           36,864\n",
      "│    │    └─BatchNorm2d: 3-24            [1, 64, 32, 32]           128\n",
      "│    │    └─ReLU: 3-25                   [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-26                 [1, 256, 32, 32]          16,384\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 256, 32, 32]          512\n",
      "│    │    └─ReLU: 3-28                   [1, 256, 32, 32]          --\n",
      "├─Sequential: 1-5                        [1, 512, 16, 16]          --\n",
      "│    └─Bottleneck: 2-4                   [1, 512, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-29                 [1, 128, 32, 32]          32,768\n",
      "│    │    └─BatchNorm2d: 3-30            [1, 128, 32, 32]          256\n",
      "│    │    └─ReLU: 3-31                   [1, 128, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-32                 [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-33            [1, 128, 16, 16]          256\n",
      "│    │    └─ReLU: 3-34                   [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-35                 [1, 512, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-36            [1, 512, 16, 16]          1,024\n",
      "│    │    └─Sequential: 3-37             [1, 512, 16, 16]          132,096\n",
      "│    │    └─ReLU: 3-38                   [1, 512, 16, 16]          --\n",
      "│    └─Bottleneck: 2-5                   [1, 512, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-39                 [1, 128, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-40            [1, 128, 16, 16]          256\n",
      "│    │    └─ReLU: 3-41                   [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-42                 [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-43            [1, 128, 16, 16]          256\n",
      "│    │    └─ReLU: 3-44                   [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-45                 [1, 512, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-46            [1, 512, 16, 16]          1,024\n",
      "│    │    └─ReLU: 3-47                   [1, 512, 16, 16]          --\n",
      "│    └─Bottleneck: 2-6                   [1, 512, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-48                 [1, 128, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-49            [1, 128, 16, 16]          256\n",
      "│    │    └─ReLU: 3-50                   [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-51                 [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-52            [1, 128, 16, 16]          256\n",
      "│    │    └─ReLU: 3-53                   [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-54                 [1, 512, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-55            [1, 512, 16, 16]          1,024\n",
      "│    │    └─ReLU: 3-56                   [1, 512, 16, 16]          --\n",
      "│    └─Bottleneck: 2-7                   [1, 512, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-57                 [1, 128, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-58            [1, 128, 16, 16]          256\n",
      "│    │    └─ReLU: 3-59                   [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-60                 [1, 128, 16, 16]          147,456\n",
      "│    │    └─BatchNorm2d: 3-61            [1, 128, 16, 16]          256\n",
      "│    │    └─ReLU: 3-62                   [1, 128, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-63                 [1, 512, 16, 16]          65,536\n",
      "│    │    └─BatchNorm2d: 3-64            [1, 512, 16, 16]          1,024\n",
      "│    │    └─ReLU: 3-65                   [1, 512, 16, 16]          --\n",
      "├─Sequential: 1-6                        [1, 1024, 8, 8]           --\n",
      "│    └─Bottleneck: 2-8                   [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-66                 [1, 256, 16, 16]          131,072\n",
      "│    │    └─BatchNorm2d: 3-67            [1, 256, 16, 16]          512\n",
      "│    │    └─ReLU: 3-68                   [1, 256, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-69                 [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-70            [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-71                   [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-72                 [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-73            [1, 1024, 8, 8]           2,048\n",
      "│    │    └─Sequential: 3-74             [1, 1024, 8, 8]           526,336\n",
      "│    │    └─ReLU: 3-75                   [1, 1024, 8, 8]           --\n",
      "│    └─Bottleneck: 2-9                   [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-76                 [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-77            [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-78                   [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-79                 [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-80            [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-81                   [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-82                 [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-83            [1, 1024, 8, 8]           2,048\n",
      "│    │    └─ReLU: 3-84                   [1, 1024, 8, 8]           --\n",
      "│    └─Bottleneck: 2-10                  [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-85                 [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-86            [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-87                   [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-88                 [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-89            [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-90                   [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-91                 [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-92            [1, 1024, 8, 8]           2,048\n",
      "│    │    └─ReLU: 3-93                   [1, 1024, 8, 8]           --\n",
      "│    └─Bottleneck: 2-11                  [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-94                 [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-95            [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-96                   [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-97                 [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-98            [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-99                   [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-100                [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-101           [1, 1024, 8, 8]           2,048\n",
      "│    │    └─ReLU: 3-102                  [1, 1024, 8, 8]           --\n",
      "│    └─Bottleneck: 2-12                  [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-103                [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-104           [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-105                  [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-106                [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-107           [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-108                  [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-109                [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-110           [1, 1024, 8, 8]           2,048\n",
      "│    │    └─ReLU: 3-111                  [1, 1024, 8, 8]           --\n",
      "│    └─Bottleneck: 2-13                  [1, 1024, 8, 8]           --\n",
      "│    │    └─Conv2d: 3-112                [1, 256, 8, 8]            262,144\n",
      "│    │    └─BatchNorm2d: 3-113           [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-114                  [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-115                [1, 256, 8, 8]            589,824\n",
      "│    │    └─BatchNorm2d: 3-116           [1, 256, 8, 8]            512\n",
      "│    │    └─ReLU: 3-117                  [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-118                [1, 1024, 8, 8]           262,144\n",
      "│    │    └─BatchNorm2d: 3-119           [1, 1024, 8, 8]           2,048\n",
      "│    │    └─ReLU: 3-120                  [1, 1024, 8, 8]           --\n",
      "├─Sequential: 1-7                        [1, 2048, 4, 4]           --\n",
      "│    └─Bottleneck: 2-14                  [1, 2048, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-121                [1, 512, 8, 8]            524,288\n",
      "│    │    └─BatchNorm2d: 3-122           [1, 512, 8, 8]            1,024\n",
      "│    │    └─ReLU: 3-123                  [1, 512, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-124                [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-125           [1, 512, 4, 4]            1,024\n",
      "│    │    └─ReLU: 3-126                  [1, 512, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-127                [1, 2048, 4, 4]           1,048,576\n",
      "│    │    └─BatchNorm2d: 3-128           [1, 2048, 4, 4]           4,096\n",
      "│    │    └─Sequential: 3-129            [1, 2048, 4, 4]           2,101,248\n",
      "│    │    └─ReLU: 3-130                  [1, 2048, 4, 4]           --\n",
      "│    └─Bottleneck: 2-15                  [1, 2048, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-131                [1, 512, 4, 4]            1,048,576\n",
      "│    │    └─BatchNorm2d: 3-132           [1, 512, 4, 4]            1,024\n",
      "│    │    └─ReLU: 3-133                  [1, 512, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-134                [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-135           [1, 512, 4, 4]            1,024\n",
      "│    │    └─ReLU: 3-136                  [1, 512, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-137                [1, 2048, 4, 4]           1,048,576\n",
      "│    │    └─BatchNorm2d: 3-138           [1, 2048, 4, 4]           4,096\n",
      "│    │    └─ReLU: 3-139                  [1, 2048, 4, 4]           --\n",
      "│    └─Bottleneck: 2-16                  [1, 2048, 4, 4]           --\n",
      "│    │    └─Conv2d: 3-140                [1, 512, 4, 4]            1,048,576\n",
      "│    │    └─BatchNorm2d: 3-141           [1, 512, 4, 4]            1,024\n",
      "│    │    └─ReLU: 3-142                  [1, 512, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-143                [1, 512, 4, 4]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-144           [1, 512, 4, 4]            1,024\n",
      "│    │    └─ReLU: 3-145                  [1, 512, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-146                [1, 2048, 4, 4]           1,048,576\n",
      "│    │    └─BatchNorm2d: 3-147           [1, 2048, 4, 4]           4,096\n",
      "│    │    └─ReLU: 3-148                  [1, 2048, 4, 4]           --\n",
      "├─AdaptiveAvgPool2d: 1-8                 [1, 2048, 1, 1]           --\n",
      "├─Linear: 1-9                            [1, 100]                  204,900\n",
      "==========================================================================================\n",
      "Total params: 23,705,252\n",
      "Trainable params: 23,705,252\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 1.30\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 54.92\n",
      "Params size (MB): 94.82\n",
      "Estimated Total Size (MB): 149.75\n",
      "==========================================================================================\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "STARTING LR FINDER\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LEARNING RATE FINDER - RANGE TEST\n",
      "======================================================================\n",
      "Testing learning rates from 1.00e-06 to 1.00e+00\n",
      "Running for 3 epochs\n",
      "Note: Using clean data (no MixUp, no Label Smoothing)\n",
      "======================================================================\n",
      "\n",
      "LR Finder Epoch 1/3: 100%|█| 196/196 [01:58<00:00,  1.66it/s, lr=9.77e-05, loss=\n",
      "LR Finder Epoch 2/3: 100%|█| 196/196 [02:07<00:00,  1.54it/s, lr=9.77e-03, loss=\n",
      "LR Finder Epoch 3/3: 100%|█| 196/196 [02:21<00:00,  1.39it/s, lr=9.77e-01, loss=\n",
      "\n",
      "Restoring initial model and optimizer state...\n",
      "✓ LR range test completed: 588 data points collected\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LR FINDER ANALYSIS\n",
      "======================================================================\n",
      "  Method: Steepest Gradient\n",
      "  → Suggested LR: 0.070297\n",
      "  → Loss at this point: 4.2142\n",
      "\n",
      "======================================================================\n",
      "ONECYCLE LR RECOMMENDATIONS\n",
      "======================================================================\n",
      "  Max LR:  0.070297 (peak learning rate)\n",
      "  Base LR: 0.000001 (starting learning rate)\n",
      "  Ratio:   56898.7x (max_lr / base_lr)\n",
      "======================================================================\n",
      "\n",
      "✓ LR Finder plot saved to: ./checkpoint_10/lr_finder_plot.png\n",
      "\n",
      "======================================================================\n",
      "LR FINDER COMPLETED\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "UPDATING ONECYCLE SCHEDULER WITH LR FINDER RESULTS\n",
      "======================================================================\n",
      "  New max_lr:      0.070297\n",
      "  New base_lr:     0.000001\n",
      "  (base_lr will be set via div_factor = max_lr / base_lr)\n",
      "======================================================================\n",
      "\n",
      "Epoch 1 Loss=4.6187 Acc=0.93% LR=0.000770: 100%|█| 196/196 [02:24<00:00,  1.36it\n",
      "\n",
      "Test set: Average loss: 4.6141, Accuracy: 100/10000 (1.00%)\n",
      "\n",
      "*** New best model! Test Accuracy: 1.00% ***\n",
      "💾 Saved best model: ./checkpoint_10/best_model.pth\n",
      "Best Test Accuracy so far: 1.00% | Patience: 0/15\n",
      "\n",
      "Epoch 2 Loss=4.6029 Acc=1.33% LR=0.003042: 100%|█| 196/196 [02:15<00:00,  1.45it\n",
      "\n",
      "Test set: Average loss: 4.5106, Accuracy: 210/10000 (2.10%)\n",
      "\n",
      "*** New best model! Test Accuracy: 2.10% ***\n",
      "💾 Saved best model: ./checkpoint_10/best_model.pth\n",
      "Best Test Accuracy so far: 2.10% | Patience: 0/15\n",
      "\n",
      "Epoch 3 Loss=4.5376 Acc=1.95% LR=0.006718: 100%|█| 196/196 [02:15<00:00,  1.45it\n",
      "\n",
      "Test set: Average loss: 4.4942, Accuracy: 185/10000 (1.85%)\n",
      "\n",
      "Best Test Accuracy so far: 2.10% | Patience: 1/15\n",
      "\n",
      "Epoch 4 Loss=4.4342 Acc=2.41% LR=0.011638: 100%|█| 196/196 [02:17<00:00,  1.43it\n",
      "\n",
      "Test set: Average loss: 4.4402, Accuracy: 306/10000 (3.06%)\n",
      "\n",
      "*** New best model! Test Accuracy: 3.06% ***\n",
      "💾 Saved best model: ./checkpoint_10/best_model.pth\n",
      "Best Test Accuracy so far: 3.06% | Patience: 0/15\n",
      "\n",
      "Epoch 5 Loss=4.5578 Acc=3.09% LR=0.017586: 100%|█| 196/196 [02:17<00:00,  1.43it\n",
      "\n",
      "Test set: Average loss: 4.3356, Accuracy: 419/10000 (4.19%)\n",
      "\n",
      "*** New best model! Test Accuracy: 4.19% ***\n",
      "💾 Saved best model: ./checkpoint_10/best_model.pth\n",
      "Best Test Accuracy so far: 4.19% | Patience: 0/15\n",
      "\n",
      "Epoch 6 Loss=4.1111 Acc=4.63% LR=0.024302: 100%|█| 196/196 [02:22<00:00,  1.37it\n",
      "\n",
      "Test set: Average loss: 4.1174, Accuracy: 676/10000 (6.76%)\n",
      "\n",
      "*** New best model! Test Accuracy: 6.76% ***\n",
      "💾 Saved best model: ./checkpoint_10/best_model.pth\n",
      "Best Test Accuracy so far: 6.76% | Patience: 0/15\n",
      "\n",
      "Epoch 7 Loss=3.9467 Acc=7.77% LR=0.031493: 100%|█| 196/196 [02:18<00:00,  1.42it\n",
      "\n",
      "Test set: Average loss: 3.7960, Accuracy: 1174/10000 (11.74%)\n",
      "\n",
      "*** New best model! Test Accuracy: 11.74% ***\n",
      "💾 Saved best model: ./checkpoint_10/best_model.pth\n",
      "Best Test Accuracy so far: 11.74% | Patience: 0/15\n",
      "\n",
      "Epoch 8 Loss=3.9559 Acc=10.42% LR=0.034229:  37%|▎| 73/196 [00:50<01:08,  1.80it^C\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x10b8c2700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pandurang/.pyenv/versions/session8-more-trials/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/pandurang/.pyenv/versions/session8-more-trials/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1618, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/pandurang/.pyenv/versions/3.12.3/lib/python3.12/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pandurang/.pyenv/versions/3.12.3/lib/python3.12/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pandurang/.pyenv/versions/3.12.3/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/pandurang/.pyenv/versions/3.12.3/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Epoch 8 Loss=4.2616 Acc=10.37% LR=0.034266:  38%|▍| 74/196 [00:50<01:23,  1.46it\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Run training with the specified configuration\n",
    "!python train.py --epochs 50 --batch-size 256 --model resnet50 --scheduler onecycle --lr-finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Complete - View Results\n",
    "\n",
    "After training completes, you can view the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List checkpoint directories\n",
    "import glob\n",
    "import json\n",
    "\n",
    "checkpoint_dirs = sorted(glob.glob('checkpoint_*'), reverse=True)\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"LATEST CHECKPOINT: {latest_checkpoint}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Load and display metrics\n",
    "    metrics_file = os.path.join(latest_checkpoint, 'metrics.json')\n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        print(f\"Best Test Accuracy: {metrics['best_test_accuracy']:.2f}%\")\n",
    "        print(f\"Best Epoch: {metrics['best_epoch']}\")\n",
    "        print(f\"Total Epochs Trained: {len(metrics['epochs'])}\")\n",
    "        print(f\"\\nFinal Metrics:\")\n",
    "        print(f\"  - Train Accuracy: {metrics['train_accuracies'][-1]:.2f}%\")\n",
    "        print(f\"  - Test Accuracy: {metrics['test_accuracies'][-1]:.2f}%\")\n",
    "        print(f\"  - Train Loss: {metrics['train_losses'][-1]:.4f}\")\n",
    "        print(f\"  - Test Loss: {metrics['test_losses'][-1]:.4f}\")\n",
    "    \n",
    "    # List saved files\n",
    "    print(f\"\\nSaved Files in {latest_checkpoint}:\")\n",
    "    for file in sorted(os.listdir(latest_checkpoint)):\n",
    "        file_path = os.path.join(latest_checkpoint, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
    "            print(f\"  - {file} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "else:\n",
    "    print(\"No checkpoint directories found. Training may not have completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    \n",
    "    # Display training curves\n",
    "    curves_path = os.path.join(latest_checkpoint, 'training_curves.png')\n",
    "    if os.path.exists(curves_path):\n",
    "        print(\"Training Curves:\")\n",
    "        display(Image(filename=curves_path))\n",
    "    else:\n",
    "        print(\"Training curves not found.\")\n",
    "    \n",
    "    # Display LR Finder plot\n",
    "    lr_finder_path = os.path.join(latest_checkpoint, 'lr_finder_plot.png')\n",
    "    if os.path.exists(lr_finder_path):\n",
    "        print(\"\\nLR Finder Plot:\")\n",
    "        display(Image(filename=lr_finder_path))\n",
    "    else:\n",
    "        print(\"LR Finder plot not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Best Model\n",
    "\n",
    "You can load the best saved model and use it for inference or further testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "\n",
    "if checkpoint_dirs:\n",
    "    latest_checkpoint = checkpoint_dirs[0]\n",
    "    best_model_path = os.path.join(latest_checkpoint, 'best_model.pth')\n",
    "    \n",
    "    if os.path.exists(best_model_path):\n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"BEST MODEL CHECKPOINT INFORMATION\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "        print(f\"Train Accuracy: {checkpoint['train_accuracy']:.2f}%\")\n",
    "        print(f\"Test Accuracy: {checkpoint['test_accuracy']:.2f}%\")\n",
    "        print(f\"Train Loss: {checkpoint['train_loss']:.4f}\")\n",
    "        print(f\"Test Loss: {checkpoint['test_loss']:.4f}\")\n",
    "        print(f\"Timestamp: {checkpoint['timestamp']}\")\n",
    "        \n",
    "        print(f\"\\nModel Configuration:\")\n",
    "        for key, value in checkpoint['config'].items():\n",
    "            print(f\"  - {key}: {value}\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Optional: Load model for inference\n",
    "        # Uncomment the following lines if you want to load the model\n",
    "        # model_module = importlib.import_module('resnet50')\n",
    "        # model = model_module.Net()\n",
    "        # model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # model.eval()\n",
    "        # print(\"✓ Model loaded successfully and ready for inference\")\n",
    "    else:\n",
    "        print(\"Best model checkpoint not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training is complete! The following artifacts have been saved:\n",
    "\n",
    "- **Best Model**: `checkpoint_N/best_model.pth` - The model with the best test accuracy\n",
    "- **Training Curves**: `checkpoint_N/training_curves.png` - Visualization of training progress\n",
    "- **LR Finder Plot**: `checkpoint_N/lr_finder_plot.png` - Learning rate range test results\n",
    "- **Metrics**: `checkpoint_N/metrics.json` - Complete training history\n",
    "- **Config**: `checkpoint_N/config.json` - Training configuration\n",
    "- **Model Card**: `checkpoint_N/README.md` - Detailed model documentation\n",
    "\n",
    "You can find all checkpoints in the `checkpoint_N/` directories where N is the run number."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session8-more-trials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
