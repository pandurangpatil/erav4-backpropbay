{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.models import resnet34\n",
        "from torchsummary import summary\n",
        "\n",
        "# CIFAR-100 Mean and Std\n",
        "cifar100_mean = (0.5071, 0.4865, 0.4409)\n",
        "cifar100_std = (0.2673, 0.2564, 0.2761)\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr2KC0BGbtME",
        "outputId": "1b2752e1-bd36-460b-ef69-0ae5fd4d6ee4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kH16rnZ7wt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ee824c-5f00-4fbd-fcc6-82b56f38455e"
      },
      "source": [
        "\n",
        "\n",
        "# Custom Albumentations Transform Wrapper\n",
        "class AlbumentationsTransforms:\n",
        "    def __init__(self, mean, std):\n",
        "        self.aug = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "            A.Affine(translate_percent=0.0625, scale=(0.9, 1.1), rotate=(-7, 7), p=0.5),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5),\n",
        "            A.RandomCrop(height=28, width=28, p=0.5),\n",
        "            A.Resize(height=32, width=32),\n",
        "            A.CoarseDropout(\n",
        "                max_holes=1,\n",
        "                max_height=16, max_width=16,\n",
        "                fill_value=tuple(int(m * 255) for m in mean),  # Convert mean to 0-255\n",
        "                p=0.5\n",
        "            ),\n",
        "            A.Normalize(mean=mean, std=std),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        image = np.array(img)\n",
        "        return self.aug(image=image)[\"image\"]\n",
        "\n",
        "# Instantiate transforms\n",
        "train_transforms = AlbumentationsTransforms(mean=cifar100_mean, std=cifar100_std)\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cifar100_mean, std=cifar100_std)\n",
        "])\n",
        "\n",
        "# CIFAR-100 Dataset\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transforms)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transforms)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=5, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=5, pin_memory=True)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2303470777.py:12: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Get a batch\n",
        "batch_data, batch_label = next(iter(train_loader))\n",
        "\n",
        "# Move to CPU and detach the computation graph\n",
        "batch_data = batch_data.cpu().detach()\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "\n",
        "for i in range(12):\n",
        "    img = batch_data[i]  # shape: [3, 32, 32]\n",
        "    img = img.numpy().transpose((1, 2, 0))  # to shape [32, 32, 3]\n",
        "    img = np.clip(img, 0, 1)  # ensure valid range for display\n",
        "\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Label: {batch_label[i].item()}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "7MwdNs7Nrngt",
        "outputId": "6eaa63aa-262e-40cd-e3b2-df3ec3c558bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "# Load ResNet18 without pretrained weights\n",
        "model = resnet18(weights=None, num_classes=100).to(device)\n",
        "\n",
        "# Modify the final fully connected layer for CIFAR-100 (100 classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Print the summary (for CIFAR-100 input size)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_JMSwm0vQiV",
        "outputId": "e1459331-a7b9-43f1-9034-bd0431d7ac1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
            "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
            "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                  [-1, 100]          51,300\n",
            "================================================================\n",
            "Total params: 11,227,812\n",
            "Trainable params: 11,227,812\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.29\n",
            "Params size (MB): 42.83\n",
            "Estimated Total Size (MB): 44.13\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup_data(x, y, alpha=1.0, device='cuda'):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1.0\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n"
      ],
      "metadata": {
        "id": "W8kyBS2C8iKL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Training & Testing\n",
        "# ------------------------------\n",
        "def train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True, mixup_alpha=0.4):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if use_mixup:\n",
        "            inputs, targets_a, targets_b, lam = mixup_data(data, target, alpha=mixup_alpha, device=device)\n",
        "            outputs = model(inputs)\n",
        "            loss = lam * F.cross_entropy(outputs, targets_a) + (1 - lam) * F.cross_entropy(outputs, targets_b)\n",
        "        else:\n",
        "            outputs = model(data)\n",
        "            loss = F.cross_entropy(outputs, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Accuracy tracking (still approximate when using MixUp)\n",
        "        _, pred = outputs.max(1)\n",
        "        if use_mixup:\n",
        "            correct += lam * pred.eq(targets_a).sum().item() + (1 - lam) * pred.eq(targets_b).sum().item()\n",
        "        else:\n",
        "            correct += pred.eq(target).sum().item()\n",
        "        processed += len(data)\n",
        "\n",
        "        pbar.set_description(f\"Epoch {epoch} Loss={loss.item():.4f} Acc={100*correct/processed:.2f}\")\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({acc:.2f}%)\\n\")\n",
        "    return acc\n",
        "\n",
        "# ------------------------------\n",
        "# Run Training\n",
        "# ------------------------------\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "EPOCHS = 40\n",
        "\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.05,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True)\n",
        "    acc = test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xY1f5OOvvaAG",
        "outputId": "3ac4ea06-8d71-42bb-811f-ea833d9955e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Loss=3.4221 Acc=14.92: 100%|██████████| 391/391 [00:30<00:00, 12.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.2998, Accuracy: 2028/10000 (20.28%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Loss=3.4910 Acc=18.87: 100%|██████████| 391/391 [00:30<00:00, 12.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.1236, Accuracy: 2349/10000 (23.49%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Loss=3.3535 Acc=22.10: 100%|██████████| 391/391 [00:30<00:00, 12.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.0261, Accuracy: 2502/10000 (25.02%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Loss=3.2286 Acc=24.60: 100%|██████████| 391/391 [00:32<00:00, 11.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.9580, Accuracy: 2744/10000 (27.44%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Loss=2.6924 Acc=27.50: 100%|██████████| 391/391 [00:30<00:00, 12.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.7870, Accuracy: 2991/10000 (29.91%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Loss=2.7445 Acc=30.46: 100%|██████████| 391/391 [00:30<00:00, 12.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.6035, Accuracy: 3402/10000 (34.02%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Loss=2.4460 Acc=32.97: 100%|██████████| 391/391 [00:30<00:00, 12.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4771, Accuracy: 3616/10000 (36.16%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Loss=2.3339 Acc=35.59: 100%|██████████| 391/391 [00:31<00:00, 12.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3704, Accuracy: 3859/10000 (38.59%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Loss=2.5520 Acc=38.20: 100%|██████████| 391/391 [00:30<00:00, 12.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3657, Accuracy: 3872/10000 (38.72%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Loss=2.2250 Acc=40.52: 100%|██████████| 391/391 [00:30<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2985, Accuracy: 4087/10000 (40.87%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Loss=2.3408 Acc=42.45: 100%|██████████| 391/391 [00:29<00:00, 13.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1994, Accuracy: 4266/10000 (42.66%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Loss=2.0510 Acc=44.70: 100%|██████████| 391/391 [00:30<00:00, 13.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1202, Accuracy: 4453/10000 (44.53%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Loss=2.1098 Acc=46.50: 100%|██████████| 391/391 [00:30<00:00, 12.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1382, Accuracy: 4423/10000 (44.23%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Loss=2.0236 Acc=48.29: 100%|██████████| 391/391 [00:30<00:00, 12.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1053, Accuracy: 4550/10000 (45.50%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Loss=1.8044 Acc=49.52:  64%|██████▍   | 251/391 [00:20<00:11, 12.30it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3846335632.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3846335632.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Training & Testing\n",
        "# ------------------------------\n",
        "def train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True, mixup_alpha=0.4):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if use_mixup:\n",
        "            inputs, targets_a, targets_b, lam = mixup_data(data, target, alpha=mixup_alpha, device=device)\n",
        "            outputs = model(inputs)\n",
        "            loss = lam * F.cross_entropy(outputs, targets_a) + (1 - lam) * F.cross_entropy(outputs, targets_b)\n",
        "        else:\n",
        "            outputs = model(data)\n",
        "            loss = F.cross_entropy(outputs, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Accuracy tracking (still approximate when using MixUp)\n",
        "        _, pred = outputs.max(1)\n",
        "        if use_mixup:\n",
        "            correct += lam * pred.eq(targets_a).sum().item() + (1 - lam) * pred.eq(targets_b).sum().item()\n",
        "        else:\n",
        "            correct += pred.eq(target).sum().item()\n",
        "        processed += len(data)\n",
        "\n",
        "        pbar.set_description(f\"Epoch {epoch} Loss={loss.item():.4f} Acc={100*correct/processed:.2f}\")\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({acc:.2f}%)\\n\")\n",
        "    return acc"
      ],
      "metadata": {
        "id": "33CJfErigRHM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Run Training\n",
        "# ------------------------------\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "EPOCHS = 40\n",
        "\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.05,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True)\n",
        "    acc = test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zXkvj1v88YJ",
        "outputId": "2e06218c-dcfb-4120-8522-56fc2ae08839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Loss=4.1080 Acc=4.93: 100%|██████████| 391/391 [00:35<00:00, 11.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.8700, Accuracy: 1146/10000 (11.46%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Loss=3.7708 Acc=8.33: 100%|██████████| 391/391 [00:32<00:00, 11.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.6858, Accuracy: 1371/10000 (13.71%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Loss=3.8650 Acc=10.80: 100%|██████████| 391/391 [00:34<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.4331, Accuracy: 1931/10000 (19.31%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Loss=3.4393 Acc=13.67: 100%|██████████| 391/391 [00:33<00:00, 11.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.2391, Accuracy: 2208/10000 (22.08%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Loss=3.2511 Acc=15.54: 100%|██████████| 391/391 [00:33<00:00, 11.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.0029, Accuracy: 2696/10000 (26.96%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Loss=4.1449 Acc=17.31: 100%|██████████| 391/391 [00:33<00:00, 11.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.1769, Accuracy: 2445/10000 (24.45%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Loss=3.7653 Acc=19.57: 100%|██████████| 391/391 [00:33<00:00, 11.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.9067, Accuracy: 2835/10000 (28.35%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Loss=2.9900 Acc=21.15: 100%|██████████| 391/391 [00:33<00:00, 11.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.7548, Accuracy: 3121/10000 (31.21%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Loss=3.0817 Acc=23.03: 100%|██████████| 391/391 [00:33<00:00, 11.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.6914, Accuracy: 3391/10000 (33.91%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Loss=3.1194 Acc=24.09: 100%|██████████| 391/391 [00:33<00:00, 11.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.6683, Accuracy: 3266/10000 (32.66%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Loss=2.6397 Acc=25.52: 100%|██████████| 391/391 [00:33<00:00, 11.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5892, Accuracy: 3535/10000 (35.35%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Loss=3.4141 Acc=27.16: 100%|██████████| 391/391 [00:34<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5892, Accuracy: 3435/10000 (34.35%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Loss=3.0038 Acc=28.26: 100%|██████████| 391/391 [00:34<00:00, 11.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5131, Accuracy: 3670/10000 (36.70%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Loss=2.5250 Acc=30.06: 100%|██████████| 391/391 [00:34<00:00, 11.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4048, Accuracy: 3911/10000 (39.11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Loss=3.3204 Acc=29.31: 100%|██████████| 391/391 [00:33<00:00, 11.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3810, Accuracy: 3953/10000 (39.53%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 Loss=2.6870 Acc=31.37: 100%|██████████| 391/391 [00:33<00:00, 11.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2785, Accuracy: 4209/10000 (42.09%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 Loss=2.0350 Acc=32.29: 100%|██████████| 391/391 [00:34<00:00, 11.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2638, Accuracy: 4195/10000 (41.95%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 Loss=3.5353 Acc=31.85: 100%|██████████| 391/391 [00:37<00:00, 10.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2711, Accuracy: 4211/10000 (42.11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 Loss=2.3673 Acc=34.05: 100%|██████████| 391/391 [00:34<00:00, 11.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2630, Accuracy: 4185/10000 (41.85%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 Loss=2.4790 Acc=35.21: 100%|██████████| 391/391 [00:33<00:00, 11.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2004, Accuracy: 4419/10000 (44.19%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 Loss=2.1419 Acc=34.65: 100%|██████████| 391/391 [00:34<00:00, 11.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1757, Accuracy: 4424/10000 (44.24%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 Loss=2.7917 Acc=36.62: 100%|██████████| 391/391 [00:33<00:00, 11.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1677, Accuracy: 4446/10000 (44.46%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 Loss=2.2937 Acc=36.55: 100%|██████████| 391/391 [00:34<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1410, Accuracy: 4523/10000 (45.23%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 Loss=3.8063 Acc=37.75: 100%|██████████| 391/391 [00:34<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1330, Accuracy: 4539/10000 (45.39%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 Loss=2.1359 Acc=38.65: 100%|██████████| 391/391 [00:34<00:00, 11.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0854, Accuracy: 4642/10000 (46.42%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 Loss=2.4483 Acc=39.53: 100%|██████████| 391/391 [00:34<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0427, Accuracy: 4759/10000 (47.59%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 Loss=3.5080 Acc=39.19: 100%|██████████| 391/391 [00:33<00:00, 11.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0551, Accuracy: 4742/10000 (47.42%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 Loss=3.5178 Acc=41.78: 100%|██████████| 391/391 [00:33<00:00, 11.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9689, Accuracy: 4921/10000 (49.21%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 Loss=2.9985 Acc=42.47: 100%|██████████| 391/391 [00:34<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0152, Accuracy: 4847/10000 (48.47%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 Loss=2.8367 Acc=43.20: 100%|██████████| 391/391 [00:35<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9498, Accuracy: 4943/10000 (49.43%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31 Loss=2.3514 Acc=42.87: 100%|██████████| 391/391 [00:33<00:00, 11.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0660, Accuracy: 4857/10000 (48.57%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32 Loss=1.5283 Acc=45.01: 100%|██████████| 391/391 [00:33<00:00, 11.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9240, Accuracy: 5052/10000 (50.52%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33 Loss=1.6636 Acc=47.21: 100%|██████████| 391/391 [00:33<00:00, 11.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9262, Accuracy: 5089/10000 (50.89%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34 Loss=2.5289 Acc=45.95: 100%|██████████| 391/391 [00:35<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8795, Accuracy: 5163/10000 (51.63%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35 Loss=3.3824 Acc=48.72: 100%|██████████| 391/391 [00:35<00:00, 11.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8244, Accuracy: 5267/10000 (52.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36 Loss=3.0239 Acc=50.60: 100%|██████████| 391/391 [00:34<00:00, 11.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8451, Accuracy: 5234/10000 (52.34%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37 Loss=2.1382 Acc=52.40: 100%|██████████| 391/391 [00:34<00:00, 11.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8164, Accuracy: 5307/10000 (53.07%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38 Loss=1.9740 Acc=53.36: 100%|██████████| 391/391 [00:33<00:00, 11.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7984, Accuracy: 5315/10000 (53.15%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39 Loss=3.7840 Acc=52.19: 100%|██████████| 391/391 [00:35<00:00, 10.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8411, Accuracy: 5287/10000 (52.87%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40 Loss=1.4055 Acc=53.01: 100%|██████████| 391/391 [00:35<00:00, 11.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8010, Accuracy: 5344/10000 (53.44%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "# Load ResNet18 without pretrained weights\n",
        "model = resnet34(weights=None, num_classes=100).to(device)\n",
        "\n",
        "# Modify the final fully connected layer for CIFAR-100 (100 classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Print the summary (for CIFAR-100 input size)\n",
        "summary(model, input_size=(3, 32, 32))\n",
        "\n",
        "# ------------------------------\n",
        "# Run Training\n",
        "# ------------------------------\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "EPOCHS = 40\n",
        "\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.05,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True)\n",
        "    acc = test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH4Wf9ikkJ_G",
        "outputId": "7b5f549e-67c0-4466-d7ba-4e31484627e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
            "             ReLU-21             [-1, 64, 8, 8]               0\n",
            "           Conv2d-22             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-23             [-1, 64, 8, 8]             128\n",
            "             ReLU-24             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-25             [-1, 64, 8, 8]               0\n",
            "           Conv2d-26            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-27            [-1, 128, 4, 4]             256\n",
            "             ReLU-28            [-1, 128, 4, 4]               0\n",
            "           Conv2d-29            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-30            [-1, 128, 4, 4]             256\n",
            "           Conv2d-31            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-36            [-1, 128, 4, 4]             256\n",
            "             ReLU-37            [-1, 128, 4, 4]               0\n",
            "           Conv2d-38            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-39            [-1, 128, 4, 4]             256\n",
            "             ReLU-40            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-41            [-1, 128, 4, 4]               0\n",
            "           Conv2d-42            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-43            [-1, 128, 4, 4]             256\n",
            "             ReLU-44            [-1, 128, 4, 4]               0\n",
            "           Conv2d-45            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-46            [-1, 128, 4, 4]             256\n",
            "             ReLU-47            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-48            [-1, 128, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-55            [-1, 128, 4, 4]               0\n",
            "           Conv2d-56            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-57            [-1, 256, 2, 2]             512\n",
            "             ReLU-58            [-1, 256, 2, 2]               0\n",
            "           Conv2d-59            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-60            [-1, 256, 2, 2]             512\n",
            "           Conv2d-61            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-62            [-1, 256, 2, 2]             512\n",
            "             ReLU-63            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-64            [-1, 256, 2, 2]               0\n",
            "           Conv2d-65            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-66            [-1, 256, 2, 2]             512\n",
            "             ReLU-67            [-1, 256, 2, 2]               0\n",
            "           Conv2d-68            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-69            [-1, 256, 2, 2]             512\n",
            "             ReLU-70            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-71            [-1, 256, 2, 2]               0\n",
            "           Conv2d-72            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-73            [-1, 256, 2, 2]             512\n",
            "             ReLU-74            [-1, 256, 2, 2]               0\n",
            "           Conv2d-75            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-76            [-1, 256, 2, 2]             512\n",
            "             ReLU-77            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-78            [-1, 256, 2, 2]               0\n",
            "           Conv2d-79            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-80            [-1, 256, 2, 2]             512\n",
            "             ReLU-81            [-1, 256, 2, 2]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-85            [-1, 256, 2, 2]               0\n",
            "           Conv2d-86            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-87            [-1, 256, 2, 2]             512\n",
            "             ReLU-88            [-1, 256, 2, 2]               0\n",
            "           Conv2d-89            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-90            [-1, 256, 2, 2]             512\n",
            "             ReLU-91            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-92            [-1, 256, 2, 2]               0\n",
            "           Conv2d-93            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-94            [-1, 256, 2, 2]             512\n",
            "             ReLU-95            [-1, 256, 2, 2]               0\n",
            "           Conv2d-96            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-97            [-1, 256, 2, 2]             512\n",
            "             ReLU-98            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-99            [-1, 256, 2, 2]               0\n",
            "          Conv2d-100            [-1, 512, 1, 1]       1,179,648\n",
            "     BatchNorm2d-101            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-102            [-1, 512, 1, 1]               0\n",
            "          Conv2d-103            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-104            [-1, 512, 1, 1]           1,024\n",
            "          Conv2d-105            [-1, 512, 1, 1]         131,072\n",
            "     BatchNorm2d-106            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-107            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-108            [-1, 512, 1, 1]               0\n",
            "          Conv2d-109            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-110            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-111            [-1, 512, 1, 1]               0\n",
            "          Conv2d-112            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-113            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-114            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-115            [-1, 512, 1, 1]               0\n",
            "          Conv2d-116            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-117            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-118            [-1, 512, 1, 1]               0\n",
            "          Conv2d-119            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-120            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-121            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-122            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
            "          Linear-124                  [-1, 100]          51,300\n",
            "================================================================\n",
            "Total params: 21,335,972\n",
            "Trainable params: 21,335,972\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.97\n",
            "Params size (MB): 81.39\n",
            "Estimated Total Size (MB): 83.37\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Loss=4.4827 Acc=3.83: 100%|██████████| 391/391 [00:39<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 4.1112, Accuracy: 856/10000 (8.56%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Loss=4.6035 Acc=6.69: 100%|██████████| 391/391 [00:40<00:00,  9.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.9845, Accuracy: 1241/10000 (12.41%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Loss=3.6625 Acc=8.88: 100%|██████████| 391/391 [00:39<00:00,  9.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.7173, Accuracy: 1471/10000 (14.71%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Loss=4.0104 Acc=11.02: 100%|██████████| 391/391 [00:39<00:00,  9.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.5019, Accuracy: 1825/10000 (18.25%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Loss=3.3945 Acc=13.36: 100%|██████████| 391/391 [00:40<00:00,  9.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.4572, Accuracy: 2072/10000 (20.72%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Loss=3.4253 Acc=14.88: 100%|██████████| 391/391 [00:40<00:00,  9.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.0861, Accuracy: 2471/10000 (24.71%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Loss=3.4863 Acc=16.61: 100%|██████████| 391/391 [00:39<00:00,  9.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.2807, Accuracy: 2569/10000 (25.69%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Loss=3.4991 Acc=18.12: 100%|██████████| 391/391 [00:40<00:00,  9.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.9569, Accuracy: 2661/10000 (26.61%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Loss=3.2083 Acc=19.63: 100%|██████████| 391/391 [00:40<00:00,  9.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.9831, Accuracy: 2732/10000 (27.32%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Loss=3.6236 Acc=19.59: 100%|██████████| 391/391 [00:39<00:00,  9.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.9725, Accuracy: 2794/10000 (27.94%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Loss=3.0361 Acc=21.70: 100%|██████████| 391/391 [00:39<00:00,  9.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.7515, Accuracy: 3199/10000 (31.99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Loss=2.8610 Acc=23.21: 100%|██████████| 391/391 [00:39<00:00,  9.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.8382, Accuracy: 3185/10000 (31.85%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Loss=2.6759 Acc=24.88: 100%|██████████| 391/391 [00:39<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.7116, Accuracy: 3302/10000 (33.02%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Loss=3.2159 Acc=24.52: 100%|██████████| 391/391 [00:39<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.6344, Accuracy: 3486/10000 (34.86%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Loss=2.8031 Acc=26.30: 100%|██████████| 391/391 [00:39<00:00,  9.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5478, Accuracy: 3614/10000 (36.14%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 Loss=2.4857 Acc=26.85: 100%|██████████| 391/391 [00:40<00:00,  9.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4559, Accuracy: 3714/10000 (37.14%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 Loss=2.7070 Acc=28.73: 100%|██████████| 391/391 [00:39<00:00,  9.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3927, Accuracy: 3927/10000 (39.27%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 Loss=3.4180 Acc=29.12: 100%|██████████| 391/391 [00:39<00:00,  9.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4061, Accuracy: 4018/10000 (40.18%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 Loss=3.7059 Acc=30.07: 100%|██████████| 391/391 [00:39<00:00,  9.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3484, Accuracy: 4032/10000 (40.32%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 Loss=3.2391 Acc=30.30: 100%|██████████| 391/391 [00:39<00:00,  9.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4004, Accuracy: 3938/10000 (39.38%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 Loss=2.7848 Acc=31.44: 100%|██████████| 391/391 [00:39<00:00,  9.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2915, Accuracy: 4156/10000 (41.56%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 Loss=3.8998 Acc=28.61: 100%|██████████| 391/391 [00:39<00:00,  9.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4277, Accuracy: 3855/10000 (38.55%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 Loss=2.7942 Acc=30.66: 100%|██████████| 391/391 [00:40<00:00,  9.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5103, Accuracy: 3768/10000 (37.68%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 Loss=2.6582 Acc=31.77: 100%|██████████| 391/391 [00:39<00:00,  9.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3494, Accuracy: 4086/10000 (40.86%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 Loss=3.1091 Acc=33.37: 100%|██████████| 391/391 [00:40<00:00,  9.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2785, Accuracy: 4204/10000 (42.04%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 Loss=3.1837 Acc=35.63: 100%|██████████| 391/391 [00:41<00:00,  9.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1604, Accuracy: 4483/10000 (44.83%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 Loss=2.1554 Acc=35.23: 100%|██████████| 391/391 [00:40<00:00,  9.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1305, Accuracy: 4489/10000 (44.89%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 Loss=3.1482 Acc=36.86: 100%|██████████| 391/391 [00:40<00:00,  9.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1319, Accuracy: 4561/10000 (45.61%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 Loss=2.4366 Acc=36.86: 100%|██████████| 391/391 [00:40<00:00,  9.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1457, Accuracy: 4558/10000 (45.58%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 Loss=1.7643 Acc=39.06: 100%|██████████| 391/391 [00:41<00:00,  9.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0669, Accuracy: 4653/10000 (46.53%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31 Loss=3.3755 Acc=39.15: 100%|██████████| 391/391 [00:40<00:00,  9.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0430, Accuracy: 4758/10000 (47.58%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32 Loss=2.5172 Acc=40.66: 100%|██████████| 391/391 [00:40<00:00,  9.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0140, Accuracy: 4856/10000 (48.56%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33 Loss=1.9585 Acc=41.54: 100%|██████████| 391/391 [00:39<00:00,  9.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0351, Accuracy: 4855/10000 (48.55%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34 Loss=3.9218 Acc=42.01: 100%|██████████| 391/391 [00:40<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0098, Accuracy: 4784/10000 (47.84%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35 Loss=3.9070 Acc=44.67: 100%|██████████| 391/391 [00:39<00:00,  9.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9673, Accuracy: 4930/10000 (49.30%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36 Loss=1.7384 Acc=44.02: 100%|██████████| 391/391 [00:40<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9282, Accuracy: 5067/10000 (50.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37 Loss=2.1711 Acc=45.93: 100%|██████████| 391/391 [00:41<00:00,  9.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8829, Accuracy: 5118/10000 (51.18%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38 Loss=1.4311 Acc=46.15: 100%|██████████| 391/391 [00:39<00:00,  9.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9013, Accuracy: 5101/10000 (51.01%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39 Loss=2.9695 Acc=46.72: 100%|██████████| 391/391 [00:40<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9120, Accuracy: 5087/10000 (50.87%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40 Loss=1.8613 Acc=48.24: 100%|██████████| 391/391 [00:40<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8892, Accuracy: 5117/10000 (51.17%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "# Load ResNet34 without pretrained weights\n",
        "model = resnet34(weights=None, num_classes=100).to(device)\n",
        "\n",
        "# Modify the final fully connected layer for CIFAR-100 (100 classes)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.4),  # Reduced from 0.4\n",
        "    nn.Linear(model.fc.in_features, 100),\n",
        ")\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Print the summary (for CIFAR-100 input size)\n",
        "summary(model, input_size=(3, 32, 32))\n",
        "\n",
        "# ------------------------------\n",
        "# Run Training\n",
        "# ------------------------------\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "EPOCHS = 100\n",
        "\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.05,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True)\n",
        "    acc = test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxEJColutNuL",
        "outputId": "4a43a38c-62aa-408a-9e3c-25c2ff5986b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
            "             ReLU-21             [-1, 64, 8, 8]               0\n",
            "           Conv2d-22             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-23             [-1, 64, 8, 8]             128\n",
            "             ReLU-24             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-25             [-1, 64, 8, 8]               0\n",
            "           Conv2d-26            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-27            [-1, 128, 4, 4]             256\n",
            "             ReLU-28            [-1, 128, 4, 4]               0\n",
            "           Conv2d-29            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-30            [-1, 128, 4, 4]             256\n",
            "           Conv2d-31            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-36            [-1, 128, 4, 4]             256\n",
            "             ReLU-37            [-1, 128, 4, 4]               0\n",
            "           Conv2d-38            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-39            [-1, 128, 4, 4]             256\n",
            "             ReLU-40            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-41            [-1, 128, 4, 4]               0\n",
            "           Conv2d-42            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-43            [-1, 128, 4, 4]             256\n",
            "             ReLU-44            [-1, 128, 4, 4]               0\n",
            "           Conv2d-45            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-46            [-1, 128, 4, 4]             256\n",
            "             ReLU-47            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-48            [-1, 128, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-55            [-1, 128, 4, 4]               0\n",
            "           Conv2d-56            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-57            [-1, 256, 2, 2]             512\n",
            "             ReLU-58            [-1, 256, 2, 2]               0\n",
            "           Conv2d-59            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-60            [-1, 256, 2, 2]             512\n",
            "           Conv2d-61            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-62            [-1, 256, 2, 2]             512\n",
            "             ReLU-63            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-64            [-1, 256, 2, 2]               0\n",
            "           Conv2d-65            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-66            [-1, 256, 2, 2]             512\n",
            "             ReLU-67            [-1, 256, 2, 2]               0\n",
            "           Conv2d-68            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-69            [-1, 256, 2, 2]             512\n",
            "             ReLU-70            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-71            [-1, 256, 2, 2]               0\n",
            "           Conv2d-72            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-73            [-1, 256, 2, 2]             512\n",
            "             ReLU-74            [-1, 256, 2, 2]               0\n",
            "           Conv2d-75            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-76            [-1, 256, 2, 2]             512\n",
            "             ReLU-77            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-78            [-1, 256, 2, 2]               0\n",
            "           Conv2d-79            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-80            [-1, 256, 2, 2]             512\n",
            "             ReLU-81            [-1, 256, 2, 2]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-85            [-1, 256, 2, 2]               0\n",
            "           Conv2d-86            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-87            [-1, 256, 2, 2]             512\n",
            "             ReLU-88            [-1, 256, 2, 2]               0\n",
            "           Conv2d-89            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-90            [-1, 256, 2, 2]             512\n",
            "             ReLU-91            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-92            [-1, 256, 2, 2]               0\n",
            "           Conv2d-93            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-94            [-1, 256, 2, 2]             512\n",
            "             ReLU-95            [-1, 256, 2, 2]               0\n",
            "           Conv2d-96            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-97            [-1, 256, 2, 2]             512\n",
            "             ReLU-98            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-99            [-1, 256, 2, 2]               0\n",
            "          Conv2d-100            [-1, 512, 1, 1]       1,179,648\n",
            "     BatchNorm2d-101            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-102            [-1, 512, 1, 1]               0\n",
            "          Conv2d-103            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-104            [-1, 512, 1, 1]           1,024\n",
            "          Conv2d-105            [-1, 512, 1, 1]         131,072\n",
            "     BatchNorm2d-106            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-107            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-108            [-1, 512, 1, 1]               0\n",
            "          Conv2d-109            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-110            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-111            [-1, 512, 1, 1]               0\n",
            "          Conv2d-112            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-113            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-114            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-115            [-1, 512, 1, 1]               0\n",
            "          Conv2d-116            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-117            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-118            [-1, 512, 1, 1]               0\n",
            "          Conv2d-119            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-120            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-121            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-122            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
            "         Dropout-124                  [-1, 512]               0\n",
            "          Linear-125                  [-1, 100]          51,300\n",
            "================================================================\n",
            "Total params: 21,335,972\n",
            "Trainable params: 21,335,972\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.97\n",
            "Params size (MB): 81.39\n",
            "Estimated Total Size (MB): 83.38\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Loss=4.3799 Acc=2.51: 100%|██████████| 391/391 [00:44<00:00,  8.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 4.1688, Accuracy: 681/10000 (6.81%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Loss=4.5202 Acc=5.36: 100%|██████████| 391/391 [00:41<00:00,  9.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.9373, Accuracy: 973/10000 (9.73%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Loss=4.3829 Acc=7.54: 100%|██████████| 391/391 [00:41<00:00,  9.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.7438, Accuracy: 1277/10000 (12.77%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Loss=3.8694 Acc=9.10: 100%|██████████| 391/391 [00:40<00:00,  9.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.6791, Accuracy: 1460/10000 (14.60%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Loss=4.0065 Acc=10.60: 100%|██████████| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.5067, Accuracy: 1686/10000 (16.86%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Loss=4.0046 Acc=11.90: 100%|██████████| 391/391 [00:40<00:00,  9.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.3699, Accuracy: 1933/10000 (19.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Loss=3.9693 Acc=12.62: 100%|██████████| 391/391 [00:40<00:00,  9.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.3905, Accuracy: 1945/10000 (19.45%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Loss=4.2293 Acc=14.76: 100%|██████████| 391/391 [00:40<00:00,  9.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.2141, Accuracy: 2239/10000 (22.39%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Loss=3.3406 Acc=15.65: 100%|██████████| 391/391 [00:40<00:00,  9.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.2587, Accuracy: 2356/10000 (23.56%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Loss=3.8494 Acc=16.28: 100%|██████████| 391/391 [00:41<00:00,  9.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.0697, Accuracy: 2647/10000 (26.47%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Loss=2.9224 Acc=18.33: 100%|██████████| 391/391 [00:40<00:00,  9.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.9142, Accuracy: 2813/10000 (28.13%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Loss=2.8306 Acc=19.20: 100%|██████████| 391/391 [00:41<00:00,  9.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.9173, Accuracy: 2884/10000 (28.84%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Loss=3.2951 Acc=18.31: 100%|██████████| 391/391 [00:40<00:00,  9.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.8328, Accuracy: 3086/10000 (30.86%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Loss=3.3308 Acc=20.09: 100%|██████████| 391/391 [00:40<00:00,  9.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.8272, Accuracy: 3025/10000 (30.25%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Loss=3.5174 Acc=20.95: 100%|██████████| 391/391 [00:40<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.8881, Accuracy: 3004/10000 (30.04%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 Loss=2.9290 Acc=21.54: 100%|██████████| 391/391 [00:40<00:00,  9.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.7135, Accuracy: 3266/10000 (32.66%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 Loss=4.5659 Acc=22.74: 100%|██████████| 391/391 [00:40<00:00,  9.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.5451, Accuracy: 2403/10000 (24.03%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 Loss=2.7465 Acc=22.99: 100%|██████████| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.6341, Accuracy: 3460/10000 (34.60%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 Loss=4.0916 Acc=24.29: 100%|██████████| 391/391 [00:40<00:00,  9.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.6477, Accuracy: 3386/10000 (33.86%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 Loss=3.0524 Acc=23.54: 100%|██████████| 391/391 [00:41<00:00,  9.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.7336, Accuracy: 3299/10000 (32.99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 Loss=3.4789 Acc=24.79: 100%|██████████| 391/391 [00:41<00:00,  9.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.7697, Accuracy: 3211/10000 (32.11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 Loss=3.4858 Acc=24.69: 100%|██████████| 391/391 [00:41<00:00,  9.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4957, Accuracy: 3698/10000 (36.98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 Loss=2.8586 Acc=25.83: 100%|██████████| 391/391 [00:41<00:00,  9.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4876, Accuracy: 3684/10000 (36.84%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 Loss=3.0457 Acc=25.51: 100%|██████████| 391/391 [00:41<00:00,  9.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5677, Accuracy: 3533/10000 (35.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 Loss=3.1707 Acc=25.93: 100%|██████████| 391/391 [00:41<00:00,  9.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5394, Accuracy: 3639/10000 (36.39%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 Loss=3.6851 Acc=27.21: 100%|██████████| 391/391 [00:41<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3594, Accuracy: 4024/10000 (40.24%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 Loss=2.6827 Acc=28.31: 100%|██████████| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3742, Accuracy: 3998/10000 (39.98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 Loss=3.8015 Acc=28.51: 100%|██████████| 391/391 [00:41<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4288, Accuracy: 3974/10000 (39.74%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 Loss=3.2550 Acc=28.76: 100%|██████████| 391/391 [00:41<00:00,  9.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3688, Accuracy: 3981/10000 (39.81%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 Loss=2.9683 Acc=29.64: 100%|██████████| 391/391 [00:41<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5318, Accuracy: 3643/10000 (36.43%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31 Loss=2.4178 Acc=29.93: 100%|██████████| 391/391 [00:42<00:00,  9.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2979, Accuracy: 4180/10000 (41.80%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32 Loss=3.1465 Acc=30.26: 100%|██████████| 391/391 [00:41<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3080, Accuracy: 4197/10000 (41.97%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33 Loss=2.9337 Acc=30.40: 100%|██████████| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2948, Accuracy: 4230/10000 (42.30%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34 Loss=3.9369 Acc=31.51: 100%|██████████| 391/391 [00:40<00:00,  9.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2935, Accuracy: 4318/10000 (43.18%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35 Loss=3.3666 Acc=31.93: 100%|██████████| 391/391 [00:40<00:00,  9.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2430, Accuracy: 4277/10000 (42.77%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36 Loss=2.4794 Acc=32.38: 100%|██████████| 391/391 [00:41<00:00,  9.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2610, Accuracy: 4192/10000 (41.92%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37 Loss=2.3344 Acc=32.57: 100%|██████████| 391/391 [00:41<00:00,  9.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1729, Accuracy: 4538/10000 (45.38%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38 Loss=2.1040 Acc=32.38: 100%|██████████| 391/391 [00:41<00:00,  9.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2218, Accuracy: 4446/10000 (44.46%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39 Loss=3.5264 Acc=32.99: 100%|██████████| 391/391 [00:41<00:00,  9.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2514, Accuracy: 4344/10000 (43.44%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40 Loss=2.2446 Acc=35.09: 100%|██████████| 391/391 [00:41<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2422, Accuracy: 4320/10000 (43.20%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41 Loss=3.8598 Acc=33.25: 100%|██████████| 391/391 [00:41<00:00,  9.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2388, Accuracy: 4396/10000 (43.96%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42 Loss=2.5827 Acc=34.13: 100%|██████████| 391/391 [00:41<00:00,  9.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2483, Accuracy: 4434/10000 (44.34%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43 Loss=2.0486 Acc=34.33: 100%|██████████| 391/391 [00:42<00:00,  9.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1333, Accuracy: 4567/10000 (45.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44 Loss=2.2229 Acc=34.55: 100%|██████████| 391/391 [00:41<00:00,  9.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2052, Accuracy: 4471/10000 (44.71%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45 Loss=2.1908 Acc=33.92: 100%|██████████| 391/391 [00:43<00:00,  8.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2709, Accuracy: 4312/10000 (43.12%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46 Loss=3.2081 Acc=34.45: 100%|██████████| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2474, Accuracy: 4415/10000 (44.15%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47 Loss=2.7093 Acc=34.39: 100%|██████████| 391/391 [00:41<00:00,  9.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2537, Accuracy: 4340/10000 (43.40%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48 Loss=3.1718 Acc=35.69: 100%|██████████| 391/391 [00:41<00:00,  9.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1510, Accuracy: 4611/10000 (46.11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49 Loss=2.1665 Acc=35.91: 100%|██████████| 391/391 [00:42<00:00,  9.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1414, Accuracy: 4594/10000 (45.94%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50 Loss=2.1711 Acc=35.05: 100%|██████████| 391/391 [00:40<00:00,  9.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1616, Accuracy: 4518/10000 (45.18%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51 Loss=3.0735 Acc=36.35: 100%|██████████| 391/391 [00:40<00:00,  9.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0697, Accuracy: 4684/10000 (46.84%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52 Loss=3.7749 Acc=37.25: 100%|██████████| 391/391 [00:40<00:00,  9.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0793, Accuracy: 4698/10000 (46.98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53 Loss=2.4492 Acc=35.29: 100%|██████████| 391/391 [00:40<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1058, Accuracy: 4733/10000 (47.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54 Loss=2.3862 Acc=37.41: 100%|██████████| 391/391 [00:40<00:00,  9.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0244, Accuracy: 4832/10000 (48.32%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55 Loss=2.2049 Acc=37.46: 100%|██████████| 391/391 [00:41<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1307, Accuracy: 4588/10000 (45.88%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56 Loss=3.1165 Acc=37.36: 100%|██████████| 391/391 [00:39<00:00,  9.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1215, Accuracy: 4599/10000 (45.99%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57 Loss=3.6416 Acc=37.94: 100%|██████████| 391/391 [00:40<00:00,  9.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0591, Accuracy: 4808/10000 (48.08%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58 Loss=1.9130 Acc=38.91: 100%|██████████| 391/391 [00:40<00:00,  9.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0804, Accuracy: 4743/10000 (47.43%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59 Loss=2.1427 Acc=37.25: 100%|██████████| 391/391 [00:40<00:00,  9.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0130, Accuracy: 4931/10000 (49.31%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60 Loss=2.0129 Acc=37.84: 100%|██████████| 391/391 [00:40<00:00,  9.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1066, Accuracy: 4645/10000 (46.45%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61 Loss=1.9860 Acc=38.76: 100%|██████████| 391/391 [00:40<00:00,  9.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0426, Accuracy: 4795/10000 (47.95%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62 Loss=1.7882 Acc=39.43: 100%|██████████| 391/391 [00:41<00:00,  9.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0772, Accuracy: 4733/10000 (47.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63 Loss=3.5100 Acc=39.15: 100%|██████████| 391/391 [00:40<00:00,  9.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0859, Accuracy: 4833/10000 (48.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64 Loss=3.6269 Acc=39.67: 100%|██████████| 391/391 [00:41<00:00,  9.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.1337, Accuracy: 4684/10000 (46.84%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65 Loss=3.6836 Acc=40.65: 100%|██████████| 391/391 [00:40<00:00,  9.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0173, Accuracy: 4872/10000 (48.72%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66 Loss=2.0294 Acc=40.22: 100%|██████████| 391/391 [00:40<00:00,  9.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9657, Accuracy: 5055/10000 (50.55%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67 Loss=1.8870 Acc=40.75: 100%|██████████| 391/391 [00:41<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9962, Accuracy: 4923/10000 (49.23%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68 Loss=1.8706 Acc=40.86: 100%|██████████| 391/391 [00:42<00:00,  9.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9599, Accuracy: 4941/10000 (49.41%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69 Loss=3.6456 Acc=41.51: 100%|██████████| 391/391 [00:41<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9620, Accuracy: 5022/10000 (50.22%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70 Loss=2.1718 Acc=41.91: 100%|██████████| 391/391 [00:44<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9751, Accuracy: 5048/10000 (50.48%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71 Loss=2.0582 Acc=42.55: 100%|██████████| 391/391 [00:44<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9131, Accuracy: 5084/10000 (50.84%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72 Loss=3.5524 Acc=42.70: 100%|██████████| 391/391 [00:42<00:00,  9.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9225, Accuracy: 5226/10000 (52.26%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73 Loss=3.0034 Acc=43.34: 100%|██████████| 391/391 [00:42<00:00,  9.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9233, Accuracy: 5068/10000 (50.68%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74 Loss=3.4818 Acc=42.95: 100%|██████████| 391/391 [00:42<00:00,  9.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.0065, Accuracy: 4995/10000 (49.95%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75 Loss=1.3507 Acc=44.97: 100%|██████████| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8126, Accuracy: 5321/10000 (53.21%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76 Loss=2.3392 Acc=43.39: 100%|██████████| 391/391 [00:41<00:00,  9.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.9133, Accuracy: 5184/10000 (51.84%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77 Loss=1.8452 Acc=45.37: 100%|██████████| 391/391 [00:41<00:00,  9.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8016, Accuracy: 5338/10000 (53.38%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78 Loss=2.3698 Acc=46.18: 100%|██████████| 391/391 [00:40<00:00,  9.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8664, Accuracy: 5291/10000 (52.91%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79 Loss=2.0112 Acc=46.78: 100%|██████████| 391/391 [00:40<00:00,  9.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7717, Accuracy: 5466/10000 (54.66%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80 Loss=3.1143 Acc=47.15: 100%|██████████| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7864, Accuracy: 5401/10000 (54.01%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81 Loss=1.7036 Acc=47.97: 100%|██████████| 391/391 [00:40<00:00,  9.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7535, Accuracy: 5453/10000 (54.53%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82 Loss=2.2882 Acc=48.71: 100%|██████████| 391/391 [00:41<00:00,  9.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.8205, Accuracy: 5354/10000 (53.54%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83 Loss=2.7484 Acc=47.92: 100%|██████████| 391/391 [00:41<00:00,  9.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7411, Accuracy: 5522/10000 (55.22%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84 Loss=3.1927 Acc=51.38: 100%|██████████| 391/391 [00:41<00:00,  9.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7520, Accuracy: 5504/10000 (55.04%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85 Loss=1.1969 Acc=50.61: 100%|██████████| 391/391 [00:41<00:00,  9.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7187, Accuracy: 5575/10000 (55.75%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86 Loss=1.3540 Acc=52.66: 100%|██████████| 391/391 [00:42<00:00,  9.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7203, Accuracy: 5598/10000 (55.98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87 Loss=1.0356 Acc=51.35: 100%|██████████| 391/391 [00:41<00:00,  9.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6858, Accuracy: 5702/10000 (57.02%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88 Loss=2.2885 Acc=55.39: 100%|██████████| 391/391 [00:41<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7118, Accuracy: 5647/10000 (56.47%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89 Loss=0.9146 Acc=54.32: 100%|██████████| 391/391 [00:41<00:00,  9.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.7232, Accuracy: 5686/10000 (56.86%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90 Loss=0.9410 Acc=58.00: 100%|██████████| 391/391 [00:41<00:00,  9.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6589, Accuracy: 5787/10000 (57.87%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91 Loss=1.7641 Acc=58.11: 100%|██████████| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6800, Accuracy: 5720/10000 (57.20%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92 Loss=1.1965 Acc=56.87: 100%|██████████| 391/391 [00:42<00:00,  9.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6840, Accuracy: 5755/10000 (57.55%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93 Loss=2.5605 Acc=59.29: 100%|██████████| 391/391 [00:42<00:00,  9.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6773, Accuracy: 5786/10000 (57.86%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94 Loss=1.0247 Acc=60.72: 100%|██████████| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6394, Accuracy: 5845/10000 (58.45%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95 Loss=0.6151 Acc=60.79: 100%|██████████| 391/391 [00:41<00:00,  9.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6338, Accuracy: 5847/10000 (58.47%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96 Loss=1.4532 Acc=59.25: 100%|██████████| 391/391 [00:45<00:00,  8.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6430, Accuracy: 5810/10000 (58.10%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97 Loss=0.9922 Acc=63.59: 100%|██████████| 391/391 [00:43<00:00,  9.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6142, Accuracy: 5895/10000 (58.95%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98 Loss=0.6722 Acc=63.77: 100%|██████████| 391/391 [00:43<00:00,  9.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6513, Accuracy: 5851/10000 (58.51%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99 Loss=0.5311 Acc=63.55: 100%|██████████| 391/391 [00:41<00:00,  9.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6290, Accuracy: 5859/10000 (58.59%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100 Loss=3.0378 Acc=64.39: 100%|██████████| 391/391 [00:42<00:00,  9.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.6370, Accuracy: 5872/10000 (58.72%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "# Load ResNet18 without pretrained weights\n",
        "model = resnet18(weights=None, num_classes=100).to(device)\n",
        "\n",
        "# Modify the final fully connected layer for CIFAR-100 (100 classes)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.4),  # Reduced from 0.4\n",
        "    nn.Linear(model.fc.in_features, 100),\n",
        ")\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Print the summary (for CIFAR-100 input size)\n",
        "summary(model, input_size=(3, 32, 32))\n",
        "\n",
        "# ------------------------------\n",
        "# Run Training\n",
        "# ------------------------------\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "EPOCHS = 100\n",
        "\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.05,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True)\n",
        "    acc = test(model, device, test_loader)"
      ],
      "metadata": {
        "id": "1zWsxTHDApIM",
        "outputId": "49578797-e1a7-4cc4-c031-aa8bf872b23b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
            "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
            "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "          Dropout-68                  [-1, 512]               0\n",
            "           Linear-69                  [-1, 100]          51,300\n",
            "================================================================\n",
            "Total params: 11,227,812\n",
            "Trainable params: 11,227,812\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.29\n",
            "Params size (MB): 42.83\n",
            "Estimated Total Size (MB): 44.13\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Loss=4.5250 Acc=2.60:  58%|█████▊    | 226/391 [00:21<00:19,  8.68it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improvements to Reach 74% Test Accuracy\n",
        "\n",
        "## Analysis of Previous Runs:\n",
        "- **40 epochs run (cell-5)**: Peak test accuracy 53.44% without proper MixUp training\n",
        "- **150 epochs run (new_trial)**: Peak test accuracy 55.78% but severe overfitting (train 73%+ vs test 55%)\n",
        "\n",
        "## Key Issues Identified:\n",
        "1. **Model capacity too small** - ResNet18 (11.2M params) insufficient for 100 classes\n",
        "2. **MixUp too aggressive** - Alpha=0.4 causing performance degradation\n",
        "3. **Data augmentation overlap** - ColorJitter + RandomBrightnessContrast + HueSaturationValue are redundant\n",
        "4. **Training plateaued** - Model maxed out at ~56% accuracy\n",
        "\n",
        "## Improvements Implemented Below:\n",
        "\n",
        "### 1. Model Architecture: ResNet18 → ResNet34\n",
        "- **Parameters**: 11.2M → 21.3M (nearly 2x capacity)\n",
        "- **Depth**: 18 layers → 34 layers\n",
        "- Better feature learning for 100-class classification\n",
        "\n",
        "### 2. MixUp Tuning: Alpha 0.4 → 0.2\n",
        "- Less aggressive blending\n",
        "- Previous runs showed MixUp hurt performance\n",
        "- Lower alpha = more focused training\n",
        "\n",
        "### 3. Simplified Data Augmentation\n",
        "**Removed:**\n",
        "- ColorJitter (redundant)\n",
        "- RandomBrightnessContrast (redundant)\n",
        "- HueSaturationValue (too aggressive)\n",
        "\n",
        "**Kept:**\n",
        "- HorizontalFlip (standard)\n",
        "- Affine (translation, scale, rotation)\n",
        "- RandomCrop + Resize\n",
        "- CoarseDropout (cutout)\n",
        "- Normalize\n",
        "\n",
        "### 4. Extended Training: 100 Epochs\n",
        "- More time for convergence\n",
        "- OneCycleLR for learning rate scheduling"
      ],
      "metadata": {
        "id": "iiCLV8_hbj-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplified Data Augmentation (Removed redundant color transforms)\n",
        "class SimplifiedAlbumentationsTransforms:\n",
        "    def __init__(self, mean, std):\n",
        "        self.aug = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Affine(translate_percent=0.0625, scale=(0.9, 1.1), rotate=(-7, 7), p=0.5),\n",
        "            A.RandomCrop(height=28, width=28, p=0.5),\n",
        "            A.Resize(height=32, width=32),\n",
        "            A.CoarseDropout(\n",
        "                max_holes=1,\n",
        "                max_height=16, max_width=16,\n",
        "                fill_value=tuple(int(m * 255) for m in mean),\n",
        "                p=0.5\n",
        "            ),\n",
        "            A.Normalize(mean=mean, std=std),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        image = np.array(img)\n",
        "        return self.aug(image=image)[\"image\"]\n",
        "\n",
        "# Create new datasets with simplified augmentations\n",
        "train_transforms_v2 = SimplifiedAlbumentationsTransforms(mean=cifar100_mean, std=cifar100_std)\n",
        "train_dataset_v2 = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transforms_v2)\n",
        "train_loader_v2 = DataLoader(train_dataset_v2, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cifar100_mean, std=cifar100_std)\n",
        "])\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transforms)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=5, pin_memory=True)\n",
        "\n",
        "print(\"Simplified augmentation pipeline created!\")\n",
        "print(\"Removed: ColorJitter, RandomBrightnessContrast, HueSaturationValue\")\n",
        "print(\"Kept: HorizontalFlip, Affine, RandomCrop, CoarseDropout\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCJgarKrbj-i",
        "outputId": "cb264481-beee-4973-cf7c-8ca1456caf65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-624767531.py:9: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplified augmentation pipeline created!\n",
            "Removed: ColorJitter, RandomBrightnessContrast, HueSaturationValue\n",
            "Kept: HorizontalFlip, Affine, RandomCrop, CoarseDropout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ResNet34 for CIFAR-100\n",
        "model_v2 = resnet34(weights=None, num_classes=100).to(device)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Model Upgrade: ResNet18 → ResNet34\")\n",
        "print(\"=\" * 70)\n",
        "summary(model_v2, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWET5uENbj-i",
        "outputId": "84a27aa9-7126-4a1e-aa4d-b823f7762fd2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Model Upgrade: ResNet18 → ResNet34\n",
            "======================================================================\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-20             [-1, 64, 8, 8]             128\n",
            "             ReLU-21             [-1, 64, 8, 8]               0\n",
            "           Conv2d-22             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-23             [-1, 64, 8, 8]             128\n",
            "             ReLU-24             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-25             [-1, 64, 8, 8]               0\n",
            "           Conv2d-26            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-27            [-1, 128, 4, 4]             256\n",
            "             ReLU-28            [-1, 128, 4, 4]               0\n",
            "           Conv2d-29            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-30            [-1, 128, 4, 4]             256\n",
            "           Conv2d-31            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-36            [-1, 128, 4, 4]             256\n",
            "             ReLU-37            [-1, 128, 4, 4]               0\n",
            "           Conv2d-38            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-39            [-1, 128, 4, 4]             256\n",
            "             ReLU-40            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-41            [-1, 128, 4, 4]               0\n",
            "           Conv2d-42            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-43            [-1, 128, 4, 4]             256\n",
            "             ReLU-44            [-1, 128, 4, 4]               0\n",
            "           Conv2d-45            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-46            [-1, 128, 4, 4]             256\n",
            "             ReLU-47            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-48            [-1, 128, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-55            [-1, 128, 4, 4]               0\n",
            "           Conv2d-56            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-57            [-1, 256, 2, 2]             512\n",
            "             ReLU-58            [-1, 256, 2, 2]               0\n",
            "           Conv2d-59            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-60            [-1, 256, 2, 2]             512\n",
            "           Conv2d-61            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-62            [-1, 256, 2, 2]             512\n",
            "             ReLU-63            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-64            [-1, 256, 2, 2]               0\n",
            "           Conv2d-65            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-66            [-1, 256, 2, 2]             512\n",
            "             ReLU-67            [-1, 256, 2, 2]               0\n",
            "           Conv2d-68            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-69            [-1, 256, 2, 2]             512\n",
            "             ReLU-70            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-71            [-1, 256, 2, 2]               0\n",
            "           Conv2d-72            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-73            [-1, 256, 2, 2]             512\n",
            "             ReLU-74            [-1, 256, 2, 2]               0\n",
            "           Conv2d-75            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-76            [-1, 256, 2, 2]             512\n",
            "             ReLU-77            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-78            [-1, 256, 2, 2]               0\n",
            "           Conv2d-79            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-80            [-1, 256, 2, 2]             512\n",
            "             ReLU-81            [-1, 256, 2, 2]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-85            [-1, 256, 2, 2]               0\n",
            "           Conv2d-86            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-87            [-1, 256, 2, 2]             512\n",
            "             ReLU-88            [-1, 256, 2, 2]               0\n",
            "           Conv2d-89            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-90            [-1, 256, 2, 2]             512\n",
            "             ReLU-91            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-92            [-1, 256, 2, 2]               0\n",
            "           Conv2d-93            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-94            [-1, 256, 2, 2]             512\n",
            "             ReLU-95            [-1, 256, 2, 2]               0\n",
            "           Conv2d-96            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-97            [-1, 256, 2, 2]             512\n",
            "             ReLU-98            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-99            [-1, 256, 2, 2]               0\n",
            "          Conv2d-100            [-1, 512, 1, 1]       1,179,648\n",
            "     BatchNorm2d-101            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-102            [-1, 512, 1, 1]               0\n",
            "          Conv2d-103            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-104            [-1, 512, 1, 1]           1,024\n",
            "          Conv2d-105            [-1, 512, 1, 1]         131,072\n",
            "     BatchNorm2d-106            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-107            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-108            [-1, 512, 1, 1]               0\n",
            "          Conv2d-109            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-110            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-111            [-1, 512, 1, 1]               0\n",
            "          Conv2d-112            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-113            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-114            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-115            [-1, 512, 1, 1]               0\n",
            "          Conv2d-116            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-117            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-118            [-1, 512, 1, 1]               0\n",
            "          Conv2d-119            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-120            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-121            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-122            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
            "          Linear-124                  [-1, 100]          51,300\n",
            "================================================================\n",
            "Total params: 21,335,972\n",
            "Trainable params: 21,335,972\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.97\n",
            "Params size (MB): 81.39\n",
            "Estimated Total Size (MB): 83.37\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with Improved Configuration\n",
        "# Key changes: ResNet34, Reduced MixUp (alpha=0.2), Simplified augmentation, 100 epochs\n",
        "\n",
        "optimizer_v2 = optim.SGD(model_v2.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "EPOCHS_V2 = 40\n",
        "\n",
        "scheduler_v2 = OneCycleLR(\n",
        "    optimizer_v2,\n",
        "    max_lr=0.05,\n",
        "    steps_per_epoch=len(train_loader_v2),\n",
        "    epochs=EPOCHS_V2\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Training Configuration:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Model: ResNet34 (21.3M parameters)\")\n",
        "print(f\"MixUp Alpha: 0.2 (reduced from 0.4)\")\n",
        "print(f\"Epochs: {EPOCHS_V2}\")\n",
        "print(f\"Optimizer: SGD (lr=0.01, momentum=0.9, weight_decay=1e-4)\")\n",
        "print(f\"Scheduler: OneCycleLR (max_lr=0.05)\")\n",
        "print(f\"Data Augmentation: Simplified (removed redundant color transforms)\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(1, EPOCHS_V2 + 1):\n",
        "    train(model_v2, device, train_loader_v2, optimizer_v2, scheduler_v2, epoch, use_mixup=True, mixup_alpha=0.2)\n",
        "    acc = test(model_v2, device, test_loader)\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        print(f\"*** New best accuracy: {best_acc:.2f}% ***\")\n",
        "\n",
        "    # Early stopping if target reached\n",
        "    if acc >= 74.0:\n",
        "        print(f\"\\n{'=' * 70}\")\n",
        "        print(f\"Target accuracy of 74% reached at epoch {epoch}!\")\n",
        "        print(f\"Final test accuracy: {acc:.2f}%\")\n",
        "        print(f\"{'=' * 70}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nTraining completed. Best test accuracy: {best_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OzwQF7wYbj-i",
        "outputId": "99c61c6b-c28d-4f13-9702-ef20af203648"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Training Configuration:\n",
            "======================================================================\n",
            "Model: ResNet34 (21.3M parameters)\n",
            "MixUp Alpha: 0.2 (reduced from 0.4)\n",
            "Epochs: 40\n",
            "Optimizer: SGD (lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
            "Scheduler: OneCycleLR (max_lr=0.05)\n",
            "Data Augmentation: Simplified (removed redundant color transforms)\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Loss=3.7487 Acc=6.66: 100%|██████████| 391/391 [00:35<00:00, 10.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.8757, Accuracy: 1100/10000 (11.00%)\n",
            "\n",
            "*** New best accuracy: 11.00% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Loss=3.7514 Acc=12.25: 100%|██████████| 391/391 [00:34<00:00, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.6104, Accuracy: 1564/10000 (15.64%)\n",
            "\n",
            "*** New best accuracy: 15.64% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Loss=3.8730 Acc=15.47: 100%|██████████| 391/391 [00:34<00:00, 11.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.4190, Accuracy: 1977/10000 (19.77%)\n",
            "\n",
            "*** New best accuracy: 19.77% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Loss=3.2073 Acc=18.16: 100%|██████████| 391/391 [00:35<00:00, 11.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.2032, Accuracy: 2318/10000 (23.18%)\n",
            "\n",
            "*** New best accuracy: 23.18% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Loss=3.1162 Acc=20.67: 100%|██████████| 391/391 [00:34<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.4802, Accuracy: 2391/10000 (23.91%)\n",
            "\n",
            "*** New best accuracy: 23.91% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Loss=2.8163 Acc=22.98: 100%|██████████| 391/391 [00:34<00:00, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.8450, Accuracy: 3056/10000 (30.56%)\n",
            "\n",
            "*** New best accuracy: 30.56% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Loss=2.8000 Acc=25.68: 100%|██████████| 391/391 [00:34<00:00, 11.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.7288, Accuracy: 3188/10000 (31.88%)\n",
            "\n",
            "*** New best accuracy: 31.88% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Loss=2.5254 Acc=27.74: 100%|██████████| 391/391 [00:34<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.8832, Accuracy: 3243/10000 (32.43%)\n",
            "\n",
            "*** New best accuracy: 32.43% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Loss=3.2784 Acc=30.23: 100%|██████████| 391/391 [00:34<00:00, 11.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.6290, Accuracy: 3554/10000 (35.54%)\n",
            "\n",
            "*** New best accuracy: 35.54% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Loss=3.0043 Acc=32.03: 100%|██████████| 391/391 [00:34<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.5623, Accuracy: 3427/10000 (34.27%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Loss=2.5393 Acc=33.66: 100%|██████████| 391/391 [00:34<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3158, Accuracy: 4028/10000 (40.28%)\n",
            "\n",
            "*** New best accuracy: 40.28% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Loss=2.8353 Acc=35.59: 100%|██████████| 391/391 [00:35<00:00, 11.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.3719, Accuracy: 3867/10000 (38.67%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Loss=3.8075 Acc=36.64: 100%|██████████| 391/391 [00:34<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.4736, Accuracy: 3961/10000 (39.61%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Loss=3.1262 Acc=38.18: 100%|██████████| 391/391 [00:34<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2981, Accuracy: 4110/10000 (41.10%)\n",
            "\n",
            "*** New best accuracy: 41.10% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Loss=3.5747 Acc=39.54: 100%|██████████| 391/391 [00:34<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2715, Accuracy: 4179/10000 (41.79%)\n",
            "\n",
            "*** New best accuracy: 41.79% ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 Loss=2.4041 Acc=41.79:  17%|█▋        | 65/391 [00:05<00:28, 11.58it/s]Exception in thread Thread-35 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 61, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
            "    c = SocketClient(address)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "Epoch 16 Loss=2.4041 Acc=41.79:  17%|█▋        | 66/391 [00:05<00:29, 11.09it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-418396189.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_V2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mixup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-174365245.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, scheduler, epoch, use_mixup, mixup_alpha)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_mixup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmixup_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2815\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2817\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2818\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2819\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}