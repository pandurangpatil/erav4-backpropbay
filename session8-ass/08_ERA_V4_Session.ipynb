{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": "# Training with Improved Configuration\n# Key changes: ResNet34, Reduced MixUp (alpha=0.2), Simplified augmentation, 100 epochs\n\noptimizer_v2 = optim.SGD(model_v2.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\nEPOCHS_V2 = 100\n\nscheduler_v2 = OneCycleLR(\n    optimizer_v2,\n    max_lr=0.05,\n    steps_per_epoch=len(train_loader_v2),\n    epochs=EPOCHS_V2\n)\n\nprint(\"=\" * 70)\nprint(\"Training Configuration:\")\nprint(\"=\" * 70)\nprint(f\"Model: ResNet34 (21.3M parameters)\")\nprint(f\"MixUp Alpha: 0.2 (reduced from 0.4)\")\nprint(f\"Epochs: {EPOCHS_V2}\")\nprint(f\"Optimizer: SGD (lr=0.01, momentum=0.9, weight_decay=1e-4)\")\nprint(f\"Scheduler: OneCycleLR (max_lr=0.05)\")\nprint(f\"Data Augmentation: Simplified (removed redundant color transforms)\")\nprint(\"=\" * 70)\nprint()\n\nbest_acc = 0.0\nfor epoch in range(1, EPOCHS_V2 + 1):\n    train(model_v2, device, train_loader_v2, optimizer_v2, scheduler_v2, epoch, use_mixup=True, mixup_alpha=0.2)\n    acc = test(model_v2, device, test_loader)\n    \n    if acc > best_acc:\n        best_acc = acc\n        print(f\"*** New best accuracy: {best_acc:.2f}% ***\")\n    \n    # Early stopping if target reached\n    if acc >= 74.0:\n        print(f\"\\n{'=' * 70}\")\n        print(f\"Target accuracy of 74% reached at epoch {epoch}!\")\n        print(f\"Final test accuracy: {acc:.2f}%\")\n        print(f\"{'=' * 70}\")\n        break\n\nprint(f\"\\nTraining completed. Best test accuracy: {best_acc:.2f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from torchvision.models import resnet34\n\n# Initialize ResNet34 for CIFAR-100\nmodel_v2 = resnet34(weights=None, num_classes=100).to(device)\n\nprint(\"=\" * 70)\nprint(\"Model Upgrade: ResNet18 → ResNet34\")\nprint(\"=\" * 70)\nsummary(model_v2, input_size=(3, 32, 32))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Simplified Data Augmentation (Removed redundant color transforms)\nclass SimplifiedAlbumentationsTransforms:\n    def __init__(self, mean, std):\n        self.aug = A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.Affine(translate_percent=0.0625, scale=(0.9, 1.1), rotate=(-7, 7), p=0.5),\n            A.RandomCrop(height=28, width=28, p=0.5),\n            A.Resize(height=32, width=32),\n            A.CoarseDropout(\n                max_holes=1,\n                max_height=16, max_width=16,\n                fill_value=tuple(int(m * 255) for m in mean),\n                p=0.5\n            ),\n            A.Normalize(mean=mean, std=std),\n            ToTensorV2()\n        ])\n\n    def __call__(self, img):\n        image = np.array(img)\n        return self.aug(image=image)[\"image\"]\n\n# Create new datasets with simplified augmentations\ntrain_transforms_v2 = SimplifiedAlbumentationsTransforms(mean=cifar100_mean, std=cifar100_std)\ntrain_dataset_v2 = datasets.CIFAR100(root='./data', train=True, download=False, transform=train_transforms_v2)\ntrain_loader_v2 = DataLoader(train_dataset_v2, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n\nprint(\"Simplified augmentation pipeline created!\")\nprint(\"Removed: ColorJitter, RandomBrightnessContrast, HueSaturationValue\")\nprint(\"Kept: HorizontalFlip, Affine, RandomCrop, CoarseDropout\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aO-7t1Y7-hV4"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8kH16rnZ7wt_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2a36c028-c253-48fc-f3eb-739c743b510a"
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n",
    "# CIFAR-100 Mean and Std\n",
    "cifar100_mean = (0.5071, 0.4865, 0.4409)\n",
    "cifar100_std = (0.2673, 0.2564, 0.2761)\n",
    "\n",
    "# Custom Albumentations Transform Wrapper\n",
    "class AlbumentationsTransforms:\n",
    "    def __init__(self, mean, std):\n",
    "        self.aug = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "            A.Affine(translate_percent=0.0625, scale=(0.9, 1.1), rotate=(-7, 7), p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5),\n",
    "            A.RandomCrop(height=28, width=28, p=0.5),\n",
    "            A.Resize(height=32, width=32),\n",
    "            A.CoarseDropout(\n",
    "                max_holes=1,\n",
    "                max_height=16, max_width=16,\n",
    "                fill_value=tuple(int(m * 255) for m in mean),  # Convert mean to 0-255\n",
    "                p=0.5\n",
    "            ),\n",
    "            A.Normalize(mean=mean, std=std),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        image = np.array(img)\n",
    "        return self.aug(image=image)[\"image\"]\n",
    "\n",
    "# Instantiate transforms\n",
    "train_transforms = AlbumentationsTransforms(mean=cifar100_mean, std=cifar100_std)\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=cifar100_mean, std=cifar100_std)\n",
    "])\n",
    "\n",
    "# CIFAR-100 Dataset\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transforms)\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transforms)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=5, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=5, pin_memory=True)\n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-2120757611.py:24: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "100%|██████████| 169M/169M [00:32<00:00, 5.21MB/s]\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Get a batch\n",
    "batch_data, batch_label = next(iter(train_loader))\n",
    "\n",
    "# Move to CPU and detach the computation graph\n",
    "batch_data = batch_data.cpu().detach()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "for i in range(12):\n",
    "    img = batch_data[i]  # shape: [3, 32, 32]\n",
    "    img = img.numpy().transpose((1, 2, 0))  # to shape [32, 32, 3]\n",
    "    img = np.clip(img, 0, 1)  # ensure valid range for display\n",
    "\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Label: {batch_label[i].item()}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "7MwdNs7Nrngt",
    "outputId": "bd9603a6-f622-47f1-d380-ad60e1f22840"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 12 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from torchsummary import summary\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Load ResNet18 without pretrained weights\n",
    "model = resnet18(weights=None, num_classes=100).to(device)\n",
    "\n",
    "# Modify the final fully connected layer for CIFAR-100 (100 classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, 100)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Print the summary (for CIFAR-100 input size)\n",
    "summary(model, input_size=(3, 32, 32))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_JMSwm0vQiV",
    "outputId": "e1459331-a7b9-43f1-9034-bd0431d7ac1a"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 100]          51,300\n",
      "================================================================\n",
      "Total params: 11,227,812\n",
      "Trainable params: 11,227,812\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 42.83\n",
      "Estimated Total Size (MB): 44.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def mixup_data(x, y, alpha=1.0, device='cuda'):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n"
   ],
   "metadata": {
    "id": "W8kyBS2C8iKL"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Training & Testing\n",
    "# ------------------------------\n",
    "def train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True, mixup_alpha=0.4):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if use_mixup:\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(data, target, alpha=mixup_alpha, device=device)\n",
    "            outputs = model(inputs)\n",
    "            loss = lam * F.cross_entropy(outputs, targets_a) + (1 - lam) * F.cross_entropy(outputs, targets_b)\n",
    "        else:\n",
    "            outputs = model(data)\n",
    "            loss = F.cross_entropy(outputs, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Accuracy tracking (still approximate when using MixUp)\n",
    "        _, pred = outputs.max(1)\n",
    "        if use_mixup:\n",
    "            correct += lam * pred.eq(targets_a).sum().item() + (1 - lam) * pred.eq(targets_b).sum().item()\n",
    "        else:\n",
    "            correct += pred.eq(target).sum().item()\n",
    "        processed += len(data)\n",
    "\n",
    "        pbar.set_description(f\"Epoch {epoch} Loss={loss.item():.4f} Acc={100*correct/processed:.2f}\")\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({acc:.2f}%)\\n\")\n",
    "    return acc\n",
    "\n",
    "# ------------------------------\n",
    "# Run Training\n",
    "# ------------------------------\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "EPOCHS = 40\n",
    "\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.05,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True)\n",
    "    acc = test(model, device, test_loader)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xY1f5OOvvaAG",
    "outputId": "3ac4ea06-8d71-42bb-811f-ea833d9955e0"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1 Loss=3.4221 Acc=14.92: 100%|██████████| 391/391 [00:30<00:00, 12.74it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.2998, Accuracy: 2028/10000 (20.28%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2 Loss=3.4910 Acc=18.87: 100%|██████████| 391/391 [00:30<00:00, 12.70it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.1236, Accuracy: 2349/10000 (23.49%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3 Loss=3.3535 Acc=22.10: 100%|██████████| 391/391 [00:30<00:00, 12.62it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.0261, Accuracy: 2502/10000 (25.02%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 4 Loss=3.2286 Acc=24.60: 100%|██████████| 391/391 [00:32<00:00, 11.91it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.9580, Accuracy: 2744/10000 (27.44%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 5 Loss=2.6924 Acc=27.50: 100%|██████████| 391/391 [00:30<00:00, 12.95it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.7870, Accuracy: 2991/10000 (29.91%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 6 Loss=2.7445 Acc=30.46: 100%|██████████| 391/391 [00:30<00:00, 12.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.6035, Accuracy: 3402/10000 (34.02%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 7 Loss=2.4460 Acc=32.97: 100%|██████████| 391/391 [00:30<00:00, 12.93it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.4771, Accuracy: 3616/10000 (36.16%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 8 Loss=2.3339 Acc=35.59: 100%|██████████| 391/391 [00:31<00:00, 12.26it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.3704, Accuracy: 3859/10000 (38.59%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 9 Loss=2.5520 Acc=38.20: 100%|██████████| 391/391 [00:30<00:00, 12.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.3657, Accuracy: 3872/10000 (38.72%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 10 Loss=2.2250 Acc=40.52: 100%|██████████| 391/391 [00:30<00:00, 13.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.2985, Accuracy: 4087/10000 (40.87%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 11 Loss=2.3408 Acc=42.45: 100%|██████████| 391/391 [00:29<00:00, 13.09it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.1994, Accuracy: 4266/10000 (42.66%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 12 Loss=2.0510 Acc=44.70: 100%|██████████| 391/391 [00:30<00:00, 13.03it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.1202, Accuracy: 4453/10000 (44.53%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 13 Loss=2.1098 Acc=46.50: 100%|██████████| 391/391 [00:30<00:00, 12.96it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.1382, Accuracy: 4423/10000 (44.23%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 14 Loss=2.0236 Acc=48.29: 100%|██████████| 391/391 [00:30<00:00, 12.98it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.1053, Accuracy: 4550/10000 (45.50%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 15 Loss=1.8044 Acc=49.52:  64%|██████▍   | 251/391 [00:20<00:11, 12.30it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3846335632.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-3846335632.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Training & Testing\n",
    "# ------------------------------\n",
    "def train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True, mixup_alpha=0.4):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if use_mixup:\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(data, target, alpha=mixup_alpha, device=device)\n",
    "            outputs = model(inputs)\n",
    "            loss = lam * F.cross_entropy(outputs, targets_a) + (1 - lam) * F.cross_entropy(outputs, targets_b)\n",
    "        else:\n",
    "            outputs = model(data)\n",
    "            loss = F.cross_entropy(outputs, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Accuracy tracking (still approximate when using MixUp)\n",
    "        _, pred = outputs.max(1)\n",
    "        if use_mixup:\n",
    "            correct += lam * pred.eq(targets_a).sum().item() + (1 - lam) * pred.eq(targets_b).sum().item()\n",
    "        else:\n",
    "            correct += pred.eq(target).sum().item()\n",
    "        processed += len(data)\n",
    "\n",
    "        pbar.set_description(f\"Epoch {epoch} Loss={loss.item():.4f} Acc={100*correct/processed:.2f}\")\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({acc:.2f}%)\\n\")\n",
    "    return acc\n",
    "\n",
    "# ------------------------------\n",
    "# Run Training\n",
    "# ------------------------------\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "EPOCHS = 40\n",
    "\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.05,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, device, train_loader, optimizer, scheduler, epoch, use_mixup=True)\n",
    "    acc = test(model, device, test_loader)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zXkvj1v88YJ",
    "outputId": "2e06218c-dcfb-4120-8522-56fc2ae08839"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1 Loss=4.1080 Acc=4.93: 100%|██████████| 391/391 [00:35<00:00, 11.10it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.8700, Accuracy: 1146/10000 (11.46%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2 Loss=3.7708 Acc=8.33: 100%|██████████| 391/391 [00:32<00:00, 11.87it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.6858, Accuracy: 1371/10000 (13.71%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3 Loss=3.8650 Acc=10.80: 100%|██████████| 391/391 [00:34<00:00, 11.19it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.4331, Accuracy: 1931/10000 (19.31%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 4 Loss=3.4393 Acc=13.67: 100%|██████████| 391/391 [00:33<00:00, 11.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.2391, Accuracy: 2208/10000 (22.08%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 5 Loss=3.2511 Acc=15.54: 100%|██████████| 391/391 [00:33<00:00, 11.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.0029, Accuracy: 2696/10000 (26.96%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 6 Loss=4.1449 Acc=17.31: 100%|██████████| 391/391 [00:33<00:00, 11.79it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 3.1769, Accuracy: 2445/10000 (24.45%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 7 Loss=3.7653 Acc=19.57: 100%|██████████| 391/391 [00:33<00:00, 11.70it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.9067, Accuracy: 2835/10000 (28.35%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 8 Loss=2.9900 Acc=21.15: 100%|██████████| 391/391 [00:33<00:00, 11.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.7548, Accuracy: 3121/10000 (31.21%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 9 Loss=3.0817 Acc=23.03: 100%|██████████| 391/391 [00:33<00:00, 11.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.6914, Accuracy: 3391/10000 (33.91%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 10 Loss=3.1194 Acc=24.09: 100%|██████████| 391/391 [00:33<00:00, 11.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.6683, Accuracy: 3266/10000 (32.66%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 11 Loss=2.6397 Acc=25.52: 100%|██████████| 391/391 [00:33<00:00, 11.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.5892, Accuracy: 3535/10000 (35.35%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 12 Loss=3.4141 Acc=27.16: 100%|██████████| 391/391 [00:34<00:00, 11.31it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.5892, Accuracy: 3435/10000 (34.35%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 13 Loss=3.0038 Acc=28.26: 100%|██████████| 391/391 [00:34<00:00, 11.38it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.5131, Accuracy: 3670/10000 (36.70%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 14 Loss=2.5250 Acc=30.06: 100%|██████████| 391/391 [00:34<00:00, 11.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.4048, Accuracy: 3911/10000 (39.11%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 15 Loss=3.3204 Acc=29.31: 100%|██████████| 391/391 [00:33<00:00, 11.66it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.3810, Accuracy: 3953/10000 (39.53%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 16 Loss=2.6870 Acc=31.37: 100%|██████████| 391/391 [00:33<00:00, 11.77it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.2785, Accuracy: 4209/10000 (42.09%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 17 Loss=2.0350 Acc=32.29: 100%|██████████| 391/391 [00:34<00:00, 11.47it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.2638, Accuracy: 4195/10000 (41.95%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 18 Loss=3.5353 Acc=31.85: 100%|██████████| 391/391 [00:37<00:00, 10.33it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.2711, Accuracy: 4211/10000 (42.11%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 19 Loss=2.3673 Acc=34.05: 100%|██████████| 391/391 [00:34<00:00, 11.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.2630, Accuracy: 4185/10000 (41.85%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 20 Loss=2.4790 Acc=35.21: 100%|██████████| 391/391 [00:33<00:00, 11.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.2004, Accuracy: 4419/10000 (44.19%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 21 Loss=2.1419 Acc=34.65: 100%|██████████| 391/391 [00:34<00:00, 11.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.1757, Accuracy: 4424/10000 (44.24%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 22 Loss=2.7917 Acc=36.62: 100%|██████████| 391/391 [00:33<00:00, 11.63it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.1677, Accuracy: 4446/10000 (44.46%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 23 Loss=2.2937 Acc=36.55: 100%|██████████| 391/391 [00:34<00:00, 11.19it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.1410, Accuracy: 4523/10000 (45.23%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 24 Loss=3.8063 Acc=37.75: 100%|██████████| 391/391 [00:34<00:00, 11.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.1330, Accuracy: 4539/10000 (45.39%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 25 Loss=2.1359 Acc=38.65: 100%|██████████| 391/391 [00:34<00:00, 11.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.0854, Accuracy: 4642/10000 (46.42%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 26 Loss=2.4483 Acc=39.53: 100%|██████████| 391/391 [00:34<00:00, 11.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.0427, Accuracy: 4759/10000 (47.59%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 27 Loss=3.5080 Acc=39.19: 100%|██████████| 391/391 [00:33<00:00, 11.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.0551, Accuracy: 4742/10000 (47.42%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 28 Loss=3.5178 Acc=41.78: 100%|██████████| 391/391 [00:33<00:00, 11.57it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.9689, Accuracy: 4921/10000 (49.21%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 29 Loss=2.9985 Acc=42.47: 100%|██████████| 391/391 [00:34<00:00, 11.29it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.0152, Accuracy: 4847/10000 (48.47%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 30 Loss=2.8367 Acc=43.20: 100%|██████████| 391/391 [00:35<00:00, 10.98it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.9498, Accuracy: 4943/10000 (49.43%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 31 Loss=2.3514 Acc=42.87: 100%|██████████| 391/391 [00:33<00:00, 11.84it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 2.0660, Accuracy: 4857/10000 (48.57%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 32 Loss=1.5283 Acc=45.01: 100%|██████████| 391/391 [00:33<00:00, 11.70it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.9240, Accuracy: 5052/10000 (50.52%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 33 Loss=1.6636 Acc=47.21: 100%|██████████| 391/391 [00:33<00:00, 11.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.9262, Accuracy: 5089/10000 (50.89%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 34 Loss=2.5289 Acc=45.95: 100%|██████████| 391/391 [00:35<00:00, 10.98it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.8795, Accuracy: 5163/10000 (51.63%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 35 Loss=3.3824 Acc=48.72: 100%|██████████| 391/391 [00:35<00:00, 11.17it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.8244, Accuracy: 5267/10000 (52.67%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 36 Loss=3.0239 Acc=50.60: 100%|██████████| 391/391 [00:34<00:00, 11.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.8451, Accuracy: 5234/10000 (52.34%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 37 Loss=2.1382 Acc=52.40: 100%|██████████| 391/391 [00:34<00:00, 11.48it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.8164, Accuracy: 5307/10000 (53.07%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 38 Loss=1.9740 Acc=53.36: 100%|██████████| 391/391 [00:33<00:00, 11.70it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.7984, Accuracy: 5315/10000 (53.15%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 39 Loss=3.7840 Acc=52.19: 100%|██████████| 391/391 [00:35<00:00, 10.91it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.8411, Accuracy: 5287/10000 (52.87%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 40 Loss=1.4055 Acc=53.01: 100%|██████████| 391/391 [00:35<00:00, 11.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 1.8010, Accuracy: 5344/10000 (53.44%)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Improvements to Reach 74% Test Accuracy\n\n## Analysis of Previous Runs:\n- **40 epochs run (cell-5)**: Peak test accuracy 53.44% without proper MixUp training\n- **150 epochs run (new_trial)**: Peak test accuracy 55.78% but severe overfitting (train 73%+ vs test 55%)\n\n## Key Issues Identified:\n1. **Model capacity too small** - ResNet18 (11.2M params) insufficient for 100 classes\n2. **MixUp too aggressive** - Alpha=0.4 causing performance degradation\n3. **Data augmentation overlap** - ColorJitter + RandomBrightnessContrast + HueSaturationValue are redundant\n4. **Training plateaued** - Model maxed out at ~56% accuracy\n\n## Improvements Implemented Below:\n\n### 1. Model Architecture: ResNet18 → ResNet34\n- **Parameters**: 11.2M → 21.3M (nearly 2x capacity)\n- **Depth**: 18 layers → 34 layers\n- Better feature learning for 100-class classification\n\n### 2. MixUp Tuning: Alpha 0.4 → 0.2\n- Less aggressive blending\n- Previous runs showed MixUp hurt performance\n- Lower alpha = more focused training\n\n### 3. Simplified Data Augmentation\n**Removed:**\n- ColorJitter (redundant)\n- RandomBrightnessContrast (redundant)\n- HueSaturationValue (too aggressive)\n\n**Kept:**\n- HorizontalFlip (standard)\n- Affine (translation, scale, rotation)\n- RandomCrop + Resize\n- CoarseDropout (cutout)\n- Normalize\n\n### 4. Extended Training: 100 Epochs\n- More time for convergence\n- OneCycleLR for learning rate scheduling",
   "metadata": {}
  }
 ]
}